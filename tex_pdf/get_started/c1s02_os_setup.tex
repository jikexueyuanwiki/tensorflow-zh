%!TEX program = xelatex
% Encoding: UTF8
% SEIKA 2016 ｜ seika@live.ca

% Chapter 1
% Section 1.2 OS_Setup


\section {Download and Setup   ||   下载与安装} \label{download_install}

Ⓔ \textcolor{etc}{You can install TensorFlow either from our provided binary packages or from the github source.}

Ⓒ 您可以使用我们提供的二进制包，或者源代码，安装 TensorFlow.

%
%%
\subsection {Requirements  ｜  安装需求}

Ⓔ \textcolor{etc}{The TensorFlow Python API currently supports Python 2.7 and Python 3.3+ from source.}

Ⓒ TensorFlow Python API 目前支持 Python 2.7 和 python 3.3以上版本．

Ⓔ \textcolor{etc}{The GPU version (Linux only) currently requires the Cuda Toolkit 7.0 and CUDNN 6.5 V2. Please see \hyperref[install_cuda]{Cuda installation}.}

Ⓒ 支持 GPU 运算的版本 (仅限Linux) 需要 Cuda Toolkit 7.0 和 CUDNN 6.5 V2. 具体请参考\hyperref[install_cuda]{Cuda安装}．

%
%%
\subsection {Overview  |  安装总述}

We support different ways to install TensorFlow:

TensorFlow 支持通过以下不同的方式安装：

\begin{itemize}
\item \hyperref[pip_install]{Pip Install}: \textcolor{etc}{Install TensorFlow on your machine, possibly upgrading previously installed Python packages. May impact existing Python programs on your machine.}\\
\item \hyperref[pip_install]{Pip 安装}: 在你的机器上安装TensorFlow，可能会同时更新之前安装的Python包，并且影响到你机器当前可运行的Python程序．\\
\item \hyperref[virtualenv_install]{Virtualenv Install}: \textcolor{etc}{Install TensorFlow in its own directory, not impacting any existing Python programs on your machine.}\\
\item \hyperref[virtualenv_install]{Virtualenv 安装}: 在一个独立的路径下安装TensorFlow，不会影响到你机器当前运行的Python程序．\\
\item \hyperref[docker_install]{Docker Install}: \textcolor{etc}{Run TensorFlow in a Docker container isolated from all other programs on your machine.}\\
\item \hyperref[docker_install]{Docker 安装}: 在一个独立的Docker容器中安装TensorFlow，并且不会影响到你机器上的任何其他程序．
\end{itemize}

Ⓔ \textcolor{etc}{If you are familiar with Pip, Virtualenv, or Docker, please feel free to adapt the instructions to your particular needs. The names of the pip and Docker images are listed in the corresponding installation sections.}

Ⓒ 如果你已经很熟悉Pip、Virtualenv、Docker这些工具的使用，请利用教程中提供的代码，根据你的需求安装TensorFlow．你会在下文的对应的安装教程中找到Pip或Docker安装所需的镜像．

Ⓔ \textcolor{etc}{If you encounter installation errors, see common problems for some solutions.}

Ⓒ 如果你遇到了安装错误，请参考章节\hyperref[comm_prob]{常见问题}寻找解决方案．

%
%%
\subsection {Pip Installatioin  |  Pip 安装} \label{pip_install}

Ⓔ \textcolor{etc}{\href{https://en.wikipedia.org/wiki/Pip_(package_manager)}{Pip} is a package management system used to install and manage software packages written in Python.}

Ⓒ \href{https://en.wikipedia.org/wiki/Pip_(package_manager)}{Pip} 是一个用于安装和管理Python软件包的管理系统．

Ⓔ \textcolor{etc}{The packages that will be installed or upgraded during the pip install are listed in the \href{https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py}{REQUIRED\_PACKAGES section of setup.py}}

Ⓒ 安装依赖包(\href{https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py}{REQUIRED\_PACKAGES section of setup.py}) 列出了pip安装时将会被安装或更新的库文件．

Ⓔ \textcolor{etc}{Install pip (or pip3 for python3) if it is not already installed:}

Ⓒ 如果pip尚未被安装，请使用以下代码先安装pip(如果你使用的是Python 3请安装 pip3 ):

\begin{lstlisting}[language = bash]
# Ubuntu/Linux 64-bit
$ sudo apt-get install python-pip python-dev
\end{lstlisting}

\begin{lstlisting}
# Mac OS X
$ sudo easy_install pip
\end{lstlisting}

Ⓔ \textcolor{etc}{Install TensorFlow:}

Ⓒ 安装 TensorFlow:

\begin{lstlisting}
# Ubuntu/Linux 64-bit, CPU only:
$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl
\end{lstlisting}

\begin{lstlisting}
# Ubuntu/Linux 64-bit, GPU enabled:
$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl
\end{lstlisting}

\begin{lstlisting}[language = bash]
# Mac OS X, CPU only:
$ sudo easy_install --upgrade six
$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl
\end{lstlisting}

Ⓔ \textcolor{etc}{For Python 3:}

Ⓒ 基于 Python 3 的 TensorFlow 安装:

\begin{lstlisting}
# Ubuntu/Linux 64-bit, CPU only:
$ sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp34-none-linux_x86_64.whl
\end{lstlisting}

\begin{lstlisting}
# Ubuntu/Linux 64-bit, GPU enabled:
$ sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.6.0-cp34-none-linux_x86_64.whl

\end{lstlisting}

\begin{lstlisting}[language = bash]
# Mac OS X, CPU only:
$ sudo easy_install --upgrade six
$ sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py3-none-any.whl
\end{lstlisting}

Ⓔ \textcolor{etc}{You can now test your \hyperref[test_install]{installation}.}

Ⓒ 至此你可以\hyperref[test_install]{测试安装}是否成功．


%
%%
\subsection {Virtualenv installation  |  基于 Virtualenv 安装} \label{virtualenv_install}

Ⓔ \textcolor{etc}{\href{http://docs.python-guide.org/en/latest/dev/virtualenvs/}{Virtualenv} is a tool to keep the dependencies required by different Python projects in separate places. The Virtualenv installation of TensorFlow will not override pre-existing version of the Python packages needed by TensorFlow.}

Ⓒ \href{http://docs.python-guide.org/en/latest/dev/virtualenvs/}{Virtualenv} 是一个管理在不同位置存放和调用 Python 项目所需依赖库的工具． TensorFlow 的 Virtualenv 安装不会覆盖先前已安装的 TensorFlow Python依赖包．

Ⓔ \textcolor{etc}{With \href{https://pypi.python.org/pypi/virtualenv}{Virtualenv} the installation is as follows:}

Ⓒ 基于\href{https://pypi.python.org/pypi/virtualenv}{Virtualenv}的安装分为以下几步:

\begin{itemize}
\item \textcolor{etc}{Install pip and Virtualenv.}
\item \textcolor{etc}{Create a Virtualenv environment.}
\item \textcolor{etc}{Activate the Virtualenv environment and install TensorFlow in it.}
\item \textcolor{etc}{After the install you will activate the Virtualenv environment each time you want to use TensorFlow.}
\item 安装 pip 和 Virtualenv.
\item 建立一个 Virtualenv 环境.
\item 激活这个 Virtualenv 环境，并且在此环境下安装 TensorFlow.
\item 安装完成之后，每次你需要使用 TensorFlow 之前必须激活这个 Virtualenv 环境.
\end{itemize}

Ⓔ \textcolor{etc}{Install pip and Virtualenv:}

Ⓒ 安装 pip 和 Virtualenv：

\begin{lstlisting}
# Ubuntu/Linux 64-bit
$ sudo apt-get install python-pip python-dev python-virtualenv
\end{lstlisting}

\begin{lstlisting}
# Mac OS X
$ sudo easy_install pip
$ sudo pip install --upgrade virtualenv
\end{lstlisting}

Ⓔ \textcolo{etc}{Create a Virtualenv environment in the directory} \lstinline{~/tensorflow}:

Ⓒ 在\lstinline{~/tensorflow}路径下建立一个 Virtualenv 环境：

\begin{lstlisting}
$ virtualenv --system-site-packages ~/tensorflow
\end{lstlisting}

Ⓔ \textcolor{etc}{Activate the environment and use pip to install TensorFlow inside it:}

Ⓒ 激活 Virtualenv 环境并使用pip在该环境下安装TensorFlow：

\begin{lstlisting}
$ source ~/tensorflow/bin/activate  # If using bash
$ source ~/tensorflow/bin/activate.csh  # If using csh
(tensorflow)$  # Your prompt should change

# Ubuntu/Linux 64-bit, CPU only:
(tensorflow)$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl

# Ubuntu/Linux 64-bit, GPU enabled:
(tensorflow)$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl

# Mac OS X, CPU only:
(tensorflow)$ pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
\end{lstlisting}

Ⓔ and again for python3:

\begin{lstlisting}
$ source ~/tensorflow/bin/activate  # If using bash
$ source ~/tensorflow/bin/activate.csh  # If using csh
(tensorflow)$  # Your prompt should change

# Ubuntu/Linux 64-bit, CPU only:
(tensorflow)$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp34-none-linux_x86_64.whl

# Ubuntu/Linux 64-bit, GPU enabled:
(tensorflow)$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.6.0-cp34-none-linux_x86_64.whl

# Mac OS X, CPU only:
(tensorflow)$ pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py3-none-any.whl
\end{lstlisting}

Ⓔ \textcolor{etc}{With the Virtualenv environment activated, you can now \hyperref[test_install]{test your installation}.}

Ⓒ 在 Virtualenv 环境被激活时，您可以\hyperref[test_install]{测试安装}．

Ⓔ \textcolor{etc}{When you are done using TensorFlow, deactivate the environment.}

Ⓒ 当您无需使用 TensorFlow 时，取消激活该环境．

\begin{lstlisting}
(tensorflow)$ deactivate
$  # Your prompt should change back
\end{lstlisting}

Ⓔ \textcolor{etc}{To use TensorFlow later you will have to activate the Virtualenv environment again:}

Ⓒ 如果需要再次使用 TensorFlow 您需要先再次激活 Virtualenv 环境:

\begin{lstlisting}
$ source ~/tensorflow/bin/activate  # If using bash.
$ source ~/tensorflow/bin/activate.csh  # If using csh.
(tensorflow)$  # Your prompt should change.
# Run Python programs that use TensorFlow.
...
# When you are done using TensorFlow, deactivate the environment.
(tensorflow)$ deactivate
\end{lstlisting}

%%%%%%%%%%%%%%%%
% Done to here %
%%%%%%%%%%%%%%%%

%
%%
\subsection {Docker Installation} \label{docker_install}
\href{http://docker.com/}{Docker} is a system to build self contained versions of a Linux operating system running on your machine. When you install and run TensorFlow via Docker it completely isolates the installation from pre-existing packages on your machine.

We provide 4 Docker images:

\begin{itemize}
\item \lstinline{b.gcr.io/tensorflow/tensorflow}: TensorFlow CPU binary image.
\item \lstinline{b.gcr.io/tensorflow/tensorflow:latest-devel}:CPU Binary image plus source code.
\item \lstinline{b.gcr.io/tensorflow/tensorflow:latest-gpu}:TensorFlow GPU binary image.
\item \lstinline{b.gcr.io/tensorflow/tensorflow:latest-devel-gpu}:GPU Binary image plus source code.
\end{itemize}

We also have tags with latest replaced by a released version (eg \lstinline{0.6.0-gpu}).

With Docker the installation is as follows:

\begin{itemize}
\item Install Docker on your machine.
\item Create a \href{http://docs.docker.com/engine/installation/ubuntulinux/#create-a-docker-group}{Docker group} to allow launching containers without sudo.
\item Launch a Docker container with the TensorFlow image. The image gets downloaded automatically on first launch.
\end{itemize}

See \href{http://docs.docker.com/engine/installation/}{installing Docker} for instructions on installing Docker on your machine.

After Docker is installed, launch a Docker container with the TensorFlow binary image as follows.

\begin{lstlisting}
$ docker run -it b.gcr.io/tensorflow/tensorflow
\end{lstlisting}

If you're using a container with GPU support, some additional flags must be passed to expose the GPU device to the container. For the default config, we include a \href{https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/docker_run_gpu.sh}{script} in the repo with these flags, so the command-line would look like:

\begin{lstlisting}
$ path/to/repo/tensorflow/tools/docker/docker_run_gpu.sh b.gcr.io/tensorflow/tensorflow:gpu
\end{lstlisting}

You can now \hyperref[test_install]{test your installation} within the Docker container.


%
%%
\subsection {Test the TensorFlow installation  |  测试 TensorFlow 安装} \label{test_install}

%%%
\subsubsection {(Optional, Linux) Enable GPU Support}

\textcolor{etc}{If you installed the GPU version of TensorFlow, you must also install the Cuda Toolkit~7.0 and CUDNN~6.5~V2. Please see \hyperref[install_cuda]{Cuda installation}.}

Ⓒ 如果您安装了GPU版本的TensorFlow, 您还需要安装 Cuda Toolkit~7.0 和 CUDNN~6.5~V2．请参阅\hyperref[install_cuda]{Cuda 安装}．

\textcolor{etc}{You also need to set the \lstinline{LD_LIBRARY_PATH} and \lstinline{CUDA_HOME} environment variables. Consider adding the commands below to your} \lstinline{~/.bash_profile}. \textcolor{etc}{These assume your CUDA installation is in \lstinline{/usr/local/cuda}:}

Ⓒ 您需要在先环境变量中设置\lstinline{LD_LIBRARY_PATH} 和 \lstinline{CUDA_HOME}．您可以在\lstinline{~/.bash_profile}中追加一下命令，假设您的CUDA安装位置为\lstinline{/usr/local/cuda}:

\begin{lstlisting}
export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:/usr/local/cuda/lib64"
export CUDA_HOME=/usr/local/cuda
\end{lstlisting}

%%%
\subsubsection {Run TensorFlow from the Command Line  |  从命令行运行TensorFlow}

See \hyperref[comm_prob]{common problems} if an error happens.

Ⓒ 如果遇到任何报错，请参考\hyperref[comm_prob]{常见问题}．

Open a terminal and type the following:

Ⓒ 打开终端，输入以下指令：

\begin{lstlisting}
$ python
...
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
>>> print(sess.run(hello))
Hello, TensorFlow!
>>> a = tf.constant(10)
>>> b = tf.constant(32)
>>> print(sess.run(a + b))
42
>>>
\end{lstlisting}

%%%
\subsubsection {Run a TensorFlow demo model  |  运行一个TensorFlow的演示模型}

All TensorFlow packages, including the demo models, are installed in the Python library. The exact location of the Python library depends on your system, but is usually one of:

Ⓒ 所有版本的TensorFlow的Python库中包都附带了一些演示模型． 具体位位置取决于您的系统，它们通常会在以下位置出现：

\begin{lstlisting}
/usr/local/lib/python2.7/dist-packages/tensorflow
/usr/local/lib/python2.7/site-packages/tensorflow
\end{lstlisting}

You can find out the directory with the following command:
Ⓒ 您可以用以下指令找到它的路径：

\begin{lstlisting}
$ python -c 'import site; print("\n".join(site.getsitepackages()))'
\end{lstlisting}

The simple demo model for classifying handwritten digits from the MNIST dataset is in the sub-directory \lstinline{models/image/mnist/convolutional.py}. You can run it from the command line as follows:

Ⓒ 在子目录\lstinline{models/image/mnist/convolutional.py}可以找到一个使用MNIST数据集进行手写数字识别的简单案例．您可以使用以下指令在命令行中直接运行：

\begin{lstlisting}
# Using 'python -m' to find the program in the python search path:
$ python -m tensorflow.models.image.mnist.convolutional
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
...etc...

# You can alternatively pass the path to the model program file to the python interpreter.
$ python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py
...
\end{lstlisting}


%
%%
\subsection {Installing from source}

Ⓔ \textcolor{etc}{When installing from source you will build a pip wheel that you then install using pip. You'll need pip for that, so install it as described \hyperref[pip_install]{above}.}

%%%
\subsubsection {Clone the TensorFlow repository}
\begin{lstlisting}
$ git clone --recurse-submodules https://github.com/tensorflow/tensorflow
\end{lstlisting}
\lstinline{--recurse-submodules} is required to fetch the protobuf library that TensorFlow depends on.


%%%
\subsubsection {Installation for Linux}

\paragraph{Install Bazel}

Follow instructions here to install the dependencies for Bazel. Then download bazel version 0.1.1 using the installer for your system and run the installer as mentioned there:

\begin{lstlisting}
$ chmod +x PATH_TO_INSTALL.SH
$ ./PATH_TO_INSTALL.SH --user
\end{lstlisting}

Remember to replace \lstinline{PATH_TO_INSTALL.SH} with the location where you downloaded the installer.

Finally, follow the instructions in that script to place bazel into your binary path.

\paragraph{Install other dependencies}\\

\begin{lstlisting}
$ sudo apt-get install python-numpy swig python-dev
\end{lstlisting}

\paragraph{Configure the installation}

Run the configure script at the root of the tree. The configure script asks you for the path to your python interpreter and allows (optional) configuration of the CUDA libraries (see \hyperref[install_cuda]{below}).

This step is used to locate the python and numpy header files.

\begin{lstlisting}
$ ./configure
Please specify the location of python. [Default is /usr/bin/python]:
\end{lstlisting}

\paragraph{Optional: Install CUDA (GPUs on Linux)} \label{install_cuda}

In order to build or run TensorFlow with GPU support, both Cuda Toolkit 7.0 and CUDNN 6.5 V2 from NVIDIA need to be installed.

TensorFlow GPU support requires having a GPU card with NVidia Compute Capability >= 3.5. Supported cards include but are not limited to:

\begin{itemize}
\item NVidia Titan
\item NVidia Titan X
\item NVidia K20
\item NVidia K40
\end{itemize}

Download and install Cuda Toolkit 7.0

https://developer.nvidia.com/cuda-toolkit-70

Install the toolkit into e.g. /usr/local/cuda

Download and install CUDNN Toolkit 6.5

https://developer.nvidia.com/rdp/cudnn-archive

Uncompress and copy the cudnn files into the toolkit directory. Assuming the toolkit is installed in /usr/local/cuda:

\begin{lstlisting}
tar xvzf cudnn-6.5-linux-x64-v2.tgz
sudo cp cudnn-6.5-linux-x64-v2/cudnn.h /usr/local/cuda/include
sudo cp cudnn-6.5-linux-x64-v2/libcudnn* /usr/local/cuda/lib64
\end{lstlisting}

Configure TensorFlow's canonical view of Cuda libraries

When running the configure script from the root of your source tree, select the option Y when asked to build TensorFlow with GPU support.

\begin{lstlisting}
$ ./configure
Please specify the location of python. [Default is /usr/bin/python]:
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow

Please specify the location where CUDA 7.0 toolkit is installed. Refer to
README.md for more details. [default is: /usr/local/cuda]: /usr/local/cuda

Please specify the location where CUDNN 6.5 V2 library is installed. Refer to
README.md for more details. [default is: /usr/local/cuda]: /usr/local/cuda

Setting up Cuda include
Setting up Cuda lib64
Setting up Cuda bin
Setting up Cuda nvvm
Configuration finished
\end{lstlisting}

This creates a canonical set of symbolic links to the Cuda libraries on your system. Every time you change the Cuda library paths you need to run this step again before you invoke the bazel build command.

Build your target with GPU support

From the root of your source tree, run:

\begin{lstlisting}
$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer

$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
# Lots of output. This tutorial iteratively calculates the major eigenvalue of
# a 2x2 matrix, on GPU. The last few lines look like this.
000009/000005 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]
000006/000001 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]
000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]
\end{lstlisting}

Note that "--config=cuda" is needed to enable the GPU support.

Enabling Cuda 3.0

TensorFlow officially supports Cuda devices with 3.5 and 5.2 compute capabilities. In order to enable earlier Cuda devices such as Grid K520, you need to target Cuda 3.0. This can be done through TensorFlow unofficial settings with "configure".

\begin{lstlisting}
$ TF_UNOFFICIAL_SETTING=1 ./configure

# Same as the official settings above

WARNING: You are configuring unofficial settings in TensorFlow. Because some
external libraries are not backward compatible, these settings are largely
untested and unsupported.

Please specify a list of comma-separated Cuda compute capabilities you want to
build with. You can find the compute capability of your device at:
https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases
your build time and binary size. [Default is: "3.5,5.2"]: 3.0

Setting up Cuda include
Setting up Cuda lib64
Setting up Cuda bin
Setting up Cuda nvvm
Configuration finished
\end{lstlisting}

Known issues

Although it is possible to build both Cuda and non-Cuda configs under the same source tree, we recommend to run \"bazel clean\" when switching between these two configs in the same source tree.

You have to run configure before running bazel build. Otherwise, the build will fail with a clear error message. In the future, we might consider making this more conveninent by including the configure step in our build process, given necessary bazel new feature support.


%%%
\subsubsection {Installation for Mac OS X}

We recommend using \href{http://brew.sh/}{homebrew} to install the bazel and SWIG dependencies, and installing python dependencies using easy_install or pip.

\paragraph{Dependencies}

Follow instructions here to install the dependencies for Bazel. You can then use homebrew to install bazel and SWIG:

\begin{lstlisting}
$ brew install bazel swig
\end{lstlisting}

You can install the python dependencies using easy_install or pip. Using easy_install, run

\begin{lstlisting}
$ sudo easy_install -U six
$ sudo easy_install -U numpy
$ sudo easy_install wheel
\end{lstlisting}

We also recommend the \href{https://ipython.org/}{ipython} enhanced python shell, so best install that too:

\begin{lstlisting}
$ sudo easy_install ipython
\end{lstlisting}

\paragraph{Configure the installation}

Run the \lstinline{configure} script at the root of the tree. The configure script asks you for the path to your python interpreter.

This step is used to locate the python and numpy header files.

\begin{lstlisting}
$ ./configure
Please specify the location of python. [Default is /usr/bin/python]:
Do you wish to build TensorFlow with GPU support? [y/N]
\end{lstlisting}

%%%
\subsubsection {Create the pip package and install}

\begin{lstlisting}
$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

# To build with GPU support:
$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

# The name of the .whl file will depend on your platform.
$ pip install /tmp/tensorflow_pkg/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
\end{lstlisting}

%
%%
\subsection {Train your first TensorFlow neural net model  |  训练第一个TensorFlow模型}

Ⓔ \textcolor{etc}{Starting from the root of your source tree, run:}

从根目录开始运行一下指令：

\begin{lstlisting}
$ cd tensorflow/models/image/mnist
$ python convolutional.py
Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
Initialized!
Epoch 0.00
Minibatch loss: 12.054, learning rate: 0.010000
Minibatch error: 90.6%
Validation error: 84.6%
Epoch 0.12
Minibatch loss: 3.285, learning rate: 0.010000
Minibatch error: 6.2%
Validation error: 7.0%
...
...
\end{lstlisting}


%
%%

% \subsection {Common Problems} \label{comm_prob}
\subsection {Common Problems  |  常见问题} \label{comm_prob}

%%%
\subsubsection {GPU-related issues  |  GPU有关问题}

If you encounter the following when trying to run a TensorFlow program:

\begin{lstlisting}
ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory
\end{lstlisting}

Make sure you followed the the GPU installation \hyperref[install_cuda]{instructions}.

%%%
\subsubsection {Pip installation issues  |  Pip安装中的问题}

\paragraph{\lstinline{Can't find setup.py}}

If, during pip install, you encounter an error like:

\begin{lstlisting}
...
IOError: [Errno 2] No such file or directory: '/tmp/pip-o6Tpui-build/setup.py'
\end{lstlisting}

Solution: upgrade your version of pip:

\begin{lstlisting}
pip install --upgrade pip
\end{lstlisting}

This may require sudo, depending on how pip is installed.

\paragraph{\lstinline{SSLError: SSL_VERIFY_FAILED}}

If, during pip install from a URL, you encounter an error like:

\begin{lstlisting}
...
SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed
\end{lstlisting}

Solution: Download the wheel manually via curl or wget, and pip install locally.

%%%
\subsubsection {Linux issues}

If you encounter:

\begin{lstlisting}
...
 "__add__", "__radd__",
             ^
SyntaxError: invalid syntax
\end{lstlisting}

Solution: make sure you are using Python 2.7.

%%%
\subsubsection {Mac OS X: ImportError: No module named copyreg}

On Mac OS X, you may encounter the following when importing tensorflow.

\begin{lstlisting}
>>> import tensorflow as tf
...
ImportError: No module named copyreg
\end{lstlisting}

Solution: TensorFlow depends on protobuf, which requires the Python package \lstinline{six-1.10.0}. Apple's default Python installation only provides \lstinline{six-1.4.1}.

You can resolve the issue in one of the following ways:
\begin{itemize}
\item pgrade the Python installation with the current version of \lstinline{six}:
\begin{lstlisting}
$ sudo easy_install -U six
\end{lstlisting}

\item Install TensorFlow with a separate Python library:
  \begin{itemize}
  \item Virtualenv
  \item Docker
  \end{itemize}
Install a separate copy of Python via Homebrew or MacPorts and re-install TensorFlow in that copy of Python.
\end{itemize}




%%%
\subsubsection {Mac OS X: TypeError: \lstinline{__init__()} got an unexpected keyword argument 'syntax'}

On Mac OS X, you may encounter the following when importing tensorflow.

\begin{lstlisting}
>>> import tensorflow as tf
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py", line 4, in <module>
    from tensorflow.python import *
  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py", line 13, in <module>
    from tensorflow.core.framework.graph_pb2 import *
...
  File "/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py", line 22, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\"d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
\end{lstlisting}

This is due to a conflict between protobuf versions (we require protobuf 3.0.0). The best current solution is to make sure older versions of protobuf are not installed, such as:

\begin{lstlisting}
$ pip install --upgrade protobuf
\end{lstlisting}


原文：\href{http://tensorflow.org/get_started/os_setup.md}{Download and Setup}
