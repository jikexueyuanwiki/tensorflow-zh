


\section{Building Graphs} \label{building-graphs}

\subsection{Contents}\label{contents}

\subsubsection{\texorpdfstring{\protect\hyperlink{AUTOGENERATED-building-graphs}{Building
Graphs}}{Building Graphs}}\label{building-graphs-1}

\begin{itemize}
   \setlength{\parsep}{-5pt}
   \setlength{\itemsep}{-5pt}
\item \hyperref[core-graph-data-structures]{Core graph data structures}
\item \hyperref[class-tf.graph]{class \lstinline{tf.Graph}}
\item \hyperref[class-tf.operation]{class \lstinline{tf.Operation}}
\item \protect\hyperlink{Tensor}{class \lstinline{tf.Tensor}}
\item \protect\hyperlink{AUTOGENERATED-tensor-types}{Tensor types}
\item \protect\hyperlink{DType}{\lstinline{class tf.DType}}
\item \protect\hyperlink{asux5fdtype}{\lstinline{tf.as_dtype(type_value)}}
\item \protect\hyperlink{AUTOGENERATED-utility-functions}{Utility functions}
\item \protect\hyperlink{device}{\lstinline{tf.device(dev)}}
\item \protect\hyperlink{nameux5fscope}{\lstinline{tf.name_scope(name)}}
\item \protect\hyperlink{controlux5fdependencies}{\lstinline{tf.control_dependencies(control_inputs)}}
\item \protect\hyperlink{convertux5ftoux5ftensor}{\lstinline{tf.convert_to_tensor(value, dtype=None, name=None)}}
\item \protect\hyperlink{getux5fdefaultux5fgraph}{\lstinline{tf.get_default_graph()}}
\item \protect\hyperlink{importux5fgraphux5fdef}{\lstinline{tf.import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None)}}
\item \protect\hyperlink{AUTOGENERATED-graph-collections}{Graph collections}
\item \protect\hyperlink{addux5ftoux5fcollection}{\lstinline{tf.add_to_collection(name, value)}}
\item \protect\hyperlink{getux5fcollection}{\lstinline{tf.get_collection(key, scope=None)}}
\item \protect\hyperlink{GraphKeys}{\lstinline{class tf.GraphKeys}}
\item \protect\hyperlink{AUTOGENERATED-defining-new-operations}{Defining new
  operations}
\item \protect\hyperlink{RegisterGradient}{\lstinline{class tf.RegisterGradient}}
\item \protect\hyperlink{NoGradient}{\lstinline{tf.NoGradient(op_type)}}
\item \protect\hyperlink{RegisterShape}{\lstinline{class tf.RegisterShape}}
\item \protect\hyperlink{TensorShape}{\lstinline{class tf.TensorShape}}
\item \protect\hyperlink{Dimension}{\lstinline{class tf.Dimension}}
\item \protect\hyperlink{opux5fscope}{\lstinline{tf.op_scope(values, name, default_name)}}
\item \protect\hyperlink{getux5fseed}{\lstinline{tf.get_seed(op_seed)}}
\end{itemize}

Classes and functions for building TensorFlow graphs.

\subsection{Core graph data structures}\label{core-graph-data-structures}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{class tf.Graph}}{class tf.Graph }}\label{class-tf.graph}

A TensorFlow computation, represented as a dataflow graph.

A \lstinline{Graph} contains a set of
\href{../../api_docs/python/framework.md\#Operation}{\lstinline{Operation}}
objects, which represent units of computation; and
\href{../../api_docs/python/framework.md\#Tensor}{\lstinline{Tensor}}
objects, which represent the units of data that flow between operations.

A default \lstinline{Graph} is always registered, and accessible by calling
\href{../../api_docs/python/framework.md\#get_default_graph}{\lstinline{tf.get_default_graph()}}.
To add an operation to the default graph, simply call one of the
functions that defines a new \lstinline{Operation}:

\begin{lstlisting}
c = tf.constant(4.0)
assert c.graph is tf.get_default_graph()
\end{lstlisting}

Another typical usage involves the
\href{../../api_docs/python/framework.md\#Graph.as_default}{\lstinline{Graph.as_default()}}
context manager, which overrides the current default graph for the
lifetime of the context:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=} \NormalTok{tf.Graph()}
\ControlFlowTok{with} \NormalTok{g.as_default():}
  \CommentTok{# Define operations and tensors in `g`.}
  \NormalTok{c }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{30.0}\NormalTok{)}
  \ControlFlowTok{assert} \NormalTok{c.graph }\OperatorTok{is} \NormalTok{g}
\end{Highlighting}
\end{Shaded}

Important note: This class \emph{is not} thread-safe for graph
construction. All operations should be created from a single thread, or
external synchronization must be provided. Unless otherwise specified,
all methods are not thread-safe.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.__init__()}
}{tf.Graph.__init__() }}\label{tf.graph.ux5fux5finitux5fux5f}

Creates a new, empty Graph.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.as_default()}
}{tf.Graph.as_default() }}\label{tf.graph.asux5fdefault}

Returns a context manager that makes this \lstinline{Graph} the default
graph.

This method should be used if you want to create multiple graphs in the
same process. For convenience, a global default graph is provided, and
all ops will be added to this graph if you do not create a new graph
explicitly. Use this method the \lstinline{with} keyword to specify that
ops created within the scope of a block should be added to this graph.

The default graph is a property of the current thread. If you create a
new thread, and wish to use the default graph in that thread, you must
explicitly add a \lstinline{with g.as_default():} in that thread's
function.

The following code examples are equivalent:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 1. Using Graph.as_default():}
\NormalTok{g }\OperatorTok{=} \NormalTok{tf.Graph()}
\ControlFlowTok{with} \NormalTok{g.as_default():}
  \NormalTok{c }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{5.0}\NormalTok{)}
  \ControlFlowTok{assert} \NormalTok{c.graph }\OperatorTok{is} \NormalTok{g}

\CommentTok{# 2. Constructing and making default:}
\ControlFlowTok{with} \NormalTok{tf.Graph().as_default() }\ImportTok{as} \NormalTok{g:}
  \NormalTok{c }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{5.0}\NormalTok{)}
  \ControlFlowTok{assert} \NormalTok{c.graph }\OperatorTok{is} \NormalTok{g}
\end{Highlighting}
\end{Shaded}

\subparagraph{Returns: }\label{returns}

A context manager for using this graph as the default graph.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.as_graph_def(from_version=None)}
}{tf.Graph.as_graph_def(from_version=None) }}\label{tf.graph.asux5fgraphux5fdeffromux5fversionnone}

Returns a serialized \lstinline{GraphDef} representation of this graph.

The serialized \lstinline{GraphDef} can be imported into another
\lstinline{Graph} (using
\protect\hyperlink{importux5fgraphux5fdef}{\lstinline{import_graph_def()}})
or used with the \href{../../api_docs/cc/index.md}{C++ Session API}.

This method is thread-safe.

\subparagraph{Args: }\label{args}

\begin{itemize}
\tightlist
\item
  \lstinline{from_version}: Optional. If this is set, returns a
  \lstinline{GraphDef} containing only the nodes that were added to this
  graph since its \lstinline{version} property had the given value.
\end{itemize}

\subparagraph{Returns: }\label{returns-1}

A
\href{https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/framework/graph.proto}{\lstinline{GraphDef}}
protocol buffer.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.finalize()}
}{tf.Graph.finalize() }}\label{tf.graph.finalize}

Finalizes this graph, making it read-only.

After calling \lstinline{g.finalize()}, no new operations can be added to
\lstinline{g}. This method is used to ensure that no operations are added
to a graph when it is shared between multiple threads, for example when
using a
\href{../../api_docs/python/train.md\#QueueRunner}{\lstinline{QueueRunner}}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.finalized}
}{tf.Graph.finalized }}\label{tf.graph.finalized}

True if this graph has been finalized.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.control_dependencies(control_inputs)}
}{tf.Graph.control_dependencies(control_inputs) }}\label{tf.graph.controlux5fdependenciescontrolux5finputs}

Returns a context manager that specifies control dependencies.

Use with the \lstinline{with} keyword to specify that all operations
constructed within the context should have control dependencies on
\lstinline{control_inputs}. For example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{with} \NormalTok{g.control_dependencies([a, b, c]):}
  \CommentTok{# `d` and `e` will only run after `a`, `b`, and `c` have executed.}
  \NormalTok{d }\OperatorTok{=} \NormalTok{...}
  \NormalTok{e }\OperatorTok{=} \NormalTok{...}
\end{Highlighting}
\end{Shaded}

Multiple calls to \lstinline{control_dependencies()} can be nested, and in
that case a new \lstinline{Operation} will have control dependencies on the
union of \lstinline{control_inputs} from all active contexts.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{with} \NormalTok{g.control_dependencies([a, b]):}
  \CommentTok{# Ops declared here run after `a` and `b`.}
  \ControlFlowTok{with} \NormalTok{g.control_dependencies([c, d]):}
    \CommentTok{# Ops declared here run after `a`, `b`, `c`, and `d`.}
\end{Highlighting}
\end{Shaded}

\emph{N.B.} The control dependencies context applies \emph{only} to ops
that are constructed within the context. Merely using an op or tensor in
the context does not add a control dependency. The following example
illustrates this point:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# WRONG}
\KeywordTok{def} \NormalTok{my_func(pred, tensor):}
  \NormalTok{t }\OperatorTok{=} \NormalTok{tf.matmul(tensor, tensor)}
  \ControlFlowTok{with} \NormalTok{tf.control_dependencies([pred]):}
    \CommentTok{# The matmul op is created outside the context, so no control}
    \CommentTok{# dependency will be added.}
    \ControlFlowTok{return} \NormalTok{t}

\CommentTok{# RIGHT}
\KeywordTok{def} \NormalTok{my_func(pred, tensor):}
  \ControlFlowTok{with} \NormalTok{tf.control_dependencies([pred]):}
    \CommentTok{# The matmul op is created in the context, so a control dependency}
    \CommentTok{# will be added.}
    \ControlFlowTok{return} \NormalTok{tf.matmul(tensor, tensor)}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-1}

\begin{itemize}
\tightlist
\item
  \lstinline{control_inputs}: A list of \lstinline{Operation} or
  \lstinline{Tensor} objects, which must be executed or computed before
  running the operations defined in the context.
\end{itemize}

\subparagraph{Returns: }\label{returns-2}

A context manager that specifies control dependencies for all operations
constructed within the context.

\subparagraph{Raises: }\label{raises}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If \lstinline{control_inputs} is not a list of
  \lstinline{Operation} or \lstinline{Tensor} objects.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.device(device_name_or_function)}
}{tf.Graph.device(device_name_or_function) }}\label{tf.graph.devicedeviceux5fnameux5forux5ffunction}

Returns a context manager that specifies the default device to use.

The \lstinline{device_name_or_function} argument may either be a device
name string, a device function, or None:

\begin{itemize}
\tightlist
\item
  If it is a device name string, all operations constructed in this
  context will be assigned to the device with that name.
\item
  If it is a function, it will be treated as function from Operation
  objects to device name strings, and invoked each time a new Operation
  is created. The Operation will be assigned to the device with the
  returned name.
\item
  If it is None, the default device will be cleared.
\end{itemize}

For example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{with} \NormalTok{g.device(}\StringTok{'/gpu:0'}\NormalTok{):}
  \CommentTok{# All operations constructed in this context will be placed}
  \CommentTok{# on GPU 0.}
  \ControlFlowTok{with} \NormalTok{g.device(}\VariableTok{None}\NormalTok{):}
    \CommentTok{# All operations constructed in this context will have no}
    \CommentTok{# assigned device.}

\CommentTok{# Defines a function from `Operation` to device string.}
\KeywordTok{def} \NormalTok{matmul_on_gpu(n):}
  \ControlFlowTok{if} \NormalTok{n.}\BuiltInTok{type} \OperatorTok{==} \StringTok{"MatMul"}\NormalTok{:}
    \ControlFlowTok{return} \StringTok{"/gpu:0"}
  \ControlFlowTok{else}\NormalTok{:}
    \ControlFlowTok{return} \StringTok{"/cpu:0"}

\ControlFlowTok{with} \NormalTok{g.device(matmul_on_gpu):}
  \CommentTok{# All operations of type "MatMul" constructed in this context}
  \CommentTok{# will be placed on GPU 0; all other operations will be placed}
  \CommentTok{# on CPU 0.}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-2}

\begin{itemize}
\tightlist
\item
  \lstinline{device_name_or_function}: The device name or function to
  use in the context.
\end{itemize}

\subparagraph{Returns: }\label{returns-3}

A context manager that specifies the default device to use for newly
created ops.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.name_scope(name)}
}{tf.Graph.name_scope(name) }}\label{tf.graph.nameux5fscopename}

Returns a context manager that creates hierarchical names for
operations.

A graph maintains a stack of name scopes. A
\lstinline{with name_scope(...):} statement pushes a new name onto the
stack for the lifetime of the context.

The \lstinline{name} argument will be interpreted as follows:

\begin{itemize}
\tightlist
\item
  A string (not ending with `/') will create a new name scope, in which
  \lstinline{name} is appended to the prefix of all operations created in
  the context. If \lstinline{name} has been used before, it will be made
  unique by calling \lstinline{self.unique_name(name)}.
\item
  A scope previously captured from a
  \lstinline{with g.name_scope(...) as   scope:} statement will be
  treated as an ``absolute'' name scope, which makes it possible to
  re-enter existing scopes.
\item
  A value of \lstinline{None} or the empty string will reset the current
  name scope to the top-level (empty) name scope.
\end{itemize}

For example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{with} \NormalTok{tf.Graph().as_default() }\ImportTok{as} \NormalTok{g:}
  \NormalTok{c }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{5.0}\NormalTok{, name}\OperatorTok{=}\StringTok{"c"}\NormalTok{)}
  \ControlFlowTok{assert} \NormalTok{c_1.name }\OperatorTok{==} \StringTok{"c"}
  \NormalTok{c_1 }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{6.0}\NormalTok{, name}\OperatorTok{=}\StringTok{"c"}\NormalTok{)}
  \ControlFlowTok{assert} \NormalTok{c_1.name }\OperatorTok{==} \StringTok{"c_1"}

  \CommentTok{# Creates a scope called "nested"}
  \ControlFlowTok{with} \NormalTok{g.name_scope(}\StringTok{"nested"}\NormalTok{) }\ImportTok{as} \NormalTok{scope:}
    \NormalTok{nested_c }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{10.0}\NormalTok{, name}\OperatorTok{=}\StringTok{"c"}\NormalTok{)}
    \ControlFlowTok{assert} \NormalTok{nested_c.name }\OperatorTok{==} \StringTok{"nested/c"}

    \CommentTok{# Creates a nested scope called "inner".}
    \ControlFlowTok{with} \NormalTok{g.name_scope(}\StringTok{"inner"}\NormalTok{):}
      \NormalTok{nested_inner_c }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{20.0}\NormalTok{, name}\OperatorTok{=}\StringTok{"c"}\NormalTok{)}
      \ControlFlowTok{assert} \NormalTok{nested_inner_c.name }\OperatorTok{==} \StringTok{"nested/inner/c"}

    \CommentTok{# Create a nested scope called "inner_1".}
    \ControlFlowTok{with} \NormalTok{g.name_scope(}\StringTok{"inner"}\NormalTok{):}
      \NormalTok{nested_inner_1_c }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{30.0}\NormalTok{, name}\OperatorTok{=}\StringTok{"c"}\NormalTok{)}
      \ControlFlowTok{assert} \NormalTok{nested_inner_1_c.name }\OperatorTok{==} \StringTok{"nested/inner_1/c"}

      \CommentTok{# Treats `scope` as an absolute name scope, and}
      \CommentTok{# switches to the "nested/" scope.}
      \ControlFlowTok{with} \NormalTok{g.name_scope(scope):}
        \NormalTok{nested_d }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{40.0}\NormalTok{, name}\OperatorTok{=}\StringTok{"d"}\NormalTok{)}
        \ControlFlowTok{assert} \NormalTok{nested_d.name }\OperatorTok{==} \StringTok{"nested/d"}

        \ControlFlowTok{with} \NormalTok{g.name_scope(}\StringTok{""}\NormalTok{):}
          \NormalTok{e }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{50.0}\NormalTok{, name}\OperatorTok{=}\StringTok{"e"}\NormalTok{)}
          \ControlFlowTok{assert} \NormalTok{e.name }\OperatorTok{==} \StringTok{"e"}
\end{Highlighting}
\end{Shaded}

The name of the scope itself can be captured by
\lstinline{with g.name_scope(...) as scope:}, which stores the name of
the scope in the variable \lstinline{scope}. This value can be used to name
an operation that represents the overall result of executing the ops in
a scope. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{inputs }\OperatorTok{=} \NormalTok{tf.constant(...)}
\ControlFlowTok{with} \NormalTok{g.name_scope(}\StringTok{'my_layer'}\NormalTok{) }\ImportTok{as} \NormalTok{scope:}
  \NormalTok{weights }\OperatorTok{=} \NormalTok{tf.Variable(..., name}\OperatorTok{=}\StringTok{"weights"}\NormalTok{)}
  \NormalTok{biases }\OperatorTok{=} \NormalTok{tf.Variable(..., name}\OperatorTok{=}\StringTok{"biases"}\NormalTok{)}
  \NormalTok{affine }\OperatorTok{=} \NormalTok{tf.matmul(inputs, weights) }\OperatorTok{+} \NormalTok{biases}
  \NormalTok{output }\OperatorTok{=} \NormalTok{tf.nn.relu(affine, name}\OperatorTok{=}\NormalTok{scope)}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-3}

\begin{itemize}
\tightlist
\item
  \lstinline{name}: A name for the scope.
\end{itemize}

\subparagraph{Returns: }\label{returns-4}

A context manager that installs \lstinline{name} as a new name scope.

A \lstinline{Graph} instance supports an arbitrary number of
``collections'' that are identified by name. For convenience when
building a large graph, collections can store groups of related objects:
for example, the \lstinline{tf.Variable} uses a collection (named
\href{../../api_docs/python/framework.md\#GraphKeys}{\lstinline{tf.GraphKeys.VARIABLES}})
for all variables that are created during the construction of a graph.
The caller may define additional collections by specifying a new name.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.add_to_collection(name, value)}
}{tf.Graph.add_to_collection(name, value) }}\label{tf.graph.addux5ftoux5fcollectionname-value}

Stores \lstinline{value} in the collection with the given \lstinline{name}.

\subparagraph{Args: }\label{args-4}

\begin{itemize}
\tightlist
\item
  \lstinline{name}: The key for the collection. For example, the
  \lstinline{GraphKeys} class contains many standard names for collections.
\item
  \lstinline{value}: The value to add to the collection.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.get_collection(name, scope=None)}
}{tf.Graph.get_collection(name, scope=None) }}\label{tf.graph.getux5fcollectionname-scopenone}

Returns a list of values in the collection with the given \lstinline{name}.

\subparagraph{Args: }\label{args-5}

\begin{itemize}
\tightlist
\item
  \lstinline{key}: The key for the collection. For example, the
  \lstinline{GraphKeys} class contains many standard names for collections.
\item
  \lstinline{scope}: (Optional.) If supplied, the resulting list is
  filtered to include only items whose name begins with this string.
\end{itemize}

\subparagraph{Returns: }\label{returns-5}

The list of values in the collection with the given \lstinline{name}, or an
empty list if no value has been added to that collection. The list
contains the values in the order under which they were collected.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.as_graph_element(obj, allow_tensor=True, allow_operation=True)}
}{tf.Graph.as_graph_element(obj, allow_tensor=True, allow_operation=True) }}\label{tf.graph.asux5fgraphux5felementobj-allowux5ftensortrue-allowux5foperationtrue}

Returns the object referred to by \lstinline{obj}, as an \lstinline{Operation}
or \lstinline{Tensor}.

This function validates that \lstinline{obj} represents an element of this
graph, and gives an informative error message if it is not.

This function is the canonical way to get/validate an object of one of
the allowed types from an external argument reference in the Session
API.

This method may be called concurrently from multiple threads.

\subparagraph{Args: }\label{args-6}

\begin{itemize}
\tightlist
\item
  \lstinline{obj}: A \lstinline{Tensor}, an \lstinline{Operation}, or the name of
  a tensor or operation. Can also be any object with an
  \lstinline{_as_graph_element()} method that returns a value of one of
  these types.
\item
  \lstinline{allow_tensor}: If true, \lstinline{obj} may refer to a
  \lstinline{Tensor}.
\item
  \lstinline{allow_operation}: If true, \lstinline{obj} may refer to an
  \lstinline{Operation}.
\end{itemize}

\subparagraph{Returns: }\label{returns-6}

The \lstinline{Tensor} or \lstinline{Operation} in the Graph corresponding to
\lstinline{obj}.

\subparagraph{Raises: }\label{raises-1}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If \lstinline{obj} is not a type we support
  attempting to convert to types.
\item
  \lstinline{ValueError}: If \lstinline{obj} is of an appropriate type but
  invalid. For example, an invalid string.
\item
  \lstinline{KeyError}: If \lstinline{obj} is not an object in the graph.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.get_operation_by_name(name)}
}{tf.Graph.get_operation_by_name(name) }}\label{tf.graph.getux5foperationux5fbyux5fnamename}

Returns the \lstinline{Operation} with the given \lstinline{name}.

This method may be called concurrently from multiple threads.

\subparagraph{Args: }\label{args-7}

\begin{itemize}
\item \lstinline{name}: The name of the \lstinline{Operation} to return.
\end{itemize}

\subparagraph{Returns: }\label{returns-7}

The \lstinline{Operation} with the given \lstinline{name}.

\subparagraph{Raises: }\label{raises-2}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If \lstinline{name} is not a string.
\item
  \lstinline{KeyError}: If \lstinline{name} does not correspond to an
  operation in this graph.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.get_tensor_by_name(name)}
}{tf.Graph.get_tensor_by_name(name) }}\label{tf.graph.getux5ftensorux5fbyux5fnamename}

Returns the \lstinline{Tensor} with the given \lstinline{name}.

This method may be called concurrently from multiple threads.

\subparagraph{Args: }\label{args-8}

\begin{itemize}
\tightlist
\item
  \lstinline{name}: The name of the \lstinline{Tensor} to return.
\end{itemize}

\subparagraph{Returns: }\label{returns-8}

The \lstinline{Tensor} with the given \lstinline{name}.

\subparagraph{Raises: }\label{raises-3}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If \lstinline{name} is not a string.
\item
  \lstinline{KeyError}: If \lstinline{name} does not correspond to a tensor in
  this graph.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.get_operations()}
}{tf.Graph.get_operations() }}\label{tf.graph.getux5foperations}

Return the list of operations in the graph.

You can modify the operations in place, but modifications to the list
such as inserts/delete have no effect on the list of operations known to
the graph.

This method may be called concurrently from multiple threads.

\subparagraph{Returns: }\label{returns-9}

A list of Operations.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.get_default_device()}
}{tf.Graph.get_default_device() }}\label{tf.graph.getux5fdefaultux5fdevice}

Returns the default device.

\subparagraph{Returns: }\label{returns-10}

A string.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.seed}
}{tf.Graph.seed }}\label{tf.graph.seed}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.unique_name(name)}
}{tf.Graph.unique_name(name) }}\label{tf.graph.uniqueux5fnamename}

Return a unique Operation name for ``name''.

Note: You rarely need to call unique_name() directly. Most of the time
you just need to create ``with g.name_scope()'' blocks to generate
structured names.

\lstinline{unique_name} is used to generate structured names, separated by
``/'', to help identify Operations when debugging a Graph. Operation
names are displayed in error messages reported by the TensorFlow
runtime, and in various visualization tools such as TensorBoard.

\subparagraph{Args: }\label{args-9}

\begin{itemize}
\tightlist
\item
  \lstinline{name}: The name for an \lstinline{Operation}.
\end{itemize}

\subparagraph{Returns: }\label{returns-11}

A string to be passed to \lstinline{create_op()} that will be used to name
the operation being created.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.version}
}{tf.Graph.version }}\label{tf.graph.version}

Returns a version number that increases as ops are added to the graph.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.create_op(op_type, inputs, dtypes, input_types=None, name=None, attrs=None, op_def=None, compute_shapes=True)}
}{tf.Graph.create_op(op_type, inputs, dtypes, input_types=None, name=None, attrs=None, op_def=None, compute_shapes=True) }}\label{tf.graph.createux5fopopux5ftype-inputs-dtypes-inputux5ftypesnone-namenone-attrsnone-opux5fdefnone-computeux5fshapestrue}

Creates an \lstinline{Operation} in this graph.

This is a low-level interface for creating an \lstinline{Operation}. Most
programs will not call this method directly, and instead use the Python
op constructors, such as \lstinline{tf.constant()}, which add ops to the
default graph.

\subparagraph{Args: }\label{args-10}

\begin{itemize}
\tightlist
\item
  \lstinline{op_type}: The \lstinline{Operation} type to create. This
  corresponds to the \lstinline{OpDef.name} field for the proto that
  defines the operation.
\item
  \lstinline{inputs}: A list of \lstinline{Tensor} objects that will be inputs
  to the \lstinline{Operation}.
\item
  \lstinline{dtypes}: A list of \lstinline{DType} objects that will be the
  types of the tensors that the operation produces.
\item
  \lstinline{input_types}: (Optional.) A list of \lstinline{DType}s that will
  be the types of the tensors that the operation consumes. By default,
  uses the base \lstinline{DType} of each input in \lstinline{inputs}.
  Operations that expect reference-typed inputs must specify
  \lstinline{input_types} explicitly.
\item
  \lstinline{name}: (Optional.) A string name for the operation. If not
  specified, a name is generated based on \lstinline{op_type}.
\item
  \lstinline{attrs}: (Optional.) A list of \lstinline{AttrValue} protos for
  the \lstinline{attr} field of the \lstinline{NodeDef} proto that will
  represent the operation.
\item
  \lstinline{op_def}: (Optional.) The \lstinline{OpDef} proto that describes
  the \lstinline{op_type} that the operation will have.
\item
  \lstinline{compute_shapes}: (Optional.) If True, shape inference will be
  performed to compute the shapes of the outputs.
\end{itemize}

\subparagraph{Raises: }\label{raises-4}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: if any of the inputs is not a \lstinline{Tensor}.
\end{itemize}

\subparagraph{Returns: }\label{returns-12}

An \lstinline{Operation} object.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Graph.gradient_override_map(op_type_map)}
}{tf.Graph.gradient_override_map(op_type_map) }}\label{tf.graph.gradientux5foverrideux5fmapopux5ftypeux5fmap}

EXPERIMENTAL: A context manager for overriding gradient functions.

This context manager can be used to override the gradient function that
will be used for ops within the scope of the context.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{@tf.RegisterGradient}\NormalTok{(}\StringTok{"CustomSquare"}\NormalTok{)}
\KeywordTok{def} \NormalTok{_custom_square_grad(op, inputs):}
  \CommentTok{# ...}

\ControlFlowTok{with} \NormalTok{tf.Graph().as_default() }\ImportTok{as} \NormalTok{g:}
  \NormalTok{c }\OperatorTok{=} \NormalTok{tf.constant(}\FloatTok{5.0}\NormalTok{)}
  \NormalTok{s_1 }\OperatorTok{=} \NormalTok{tf.square(c)  }\CommentTok{# Uses the default gradient for tf.square.}
  \ControlFlowTok{with} \NormalTok{g.gradient_override_map(\{}\StringTok{"Square"}\NormalTok{: }\StringTok{"CustomSquare"}\NormalTok{\}):}
    \NormalTok{s_2 }\OperatorTok{=} \NormalTok{tf.square(s_2)  }\CommentTok{# Uses _custom_square_grad to compute the}
                          \CommentTok{# gradient of s_2.}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-11}

\begin{itemize}
\tightlist
\item
  \lstinline{op_type_map}: A dictionary mapping op type strings to
  alternative op type strings.
\end{itemize}

\subparagraph{Returns: }\label{returns-13}

A context manager that sets the alternative op type to be used for one
or more ops created in that context.

\subparagraph{Raises: }\label{raises-5}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If \lstinline{op_type_map} is not a dictionary
  mapping strings to strings.
\end{itemize}


\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}


\subsubsection{class \lstinline{tf.Operation}} \label{class-tf.operation}

Represents a graph node that performs computation on tensors.

An \lstinline{Operation} is a node in a TensorFlow \lstinline{Graph} that
takes zero or more \lstinline{Tensor} objects as input, and produces zero
or more \lstinline{Tensor} objects as output. Objects of type
\lstinline{Operation} are created by calling a Python op constructor (such
as
\href{../../api_docs/python/math_ops.md\#matmul}{\lstinline{tf.matmul()}})
or
\href{../../api_docs/python/framework.md\#Graph.create_op}{\lstinline{Graph.create_op()}}.

For example \lstinline{c = tf.matmul(a, b)} creates an
\lstinline{Operation} of type "MatMul" that takes tensors \lstinline{a} and
\lstinline{b} as input, and produces \lstinline{c} as output.

After the graph has been launched in a session, an \lstinline{Operation}
can be executed by passing it to
\href{../../api_docs/python/client.md\#Session.run}{\lstinline{Session.run()}}.
\lstinline{op.run()} is a shortcut for calling
\lstinline{tf.get_default_session().run(op)}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.name}
}{tf.Operation.name }}\label{tf.operation.name}

The full name of this operation.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.type}
}{tf.Operation.type }}\label{tf.operation.type}

The type of the op (e.g. \lstinline{"MatMul"}).

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.inputs}
}{tf.Operation.inputs }}\label{tf.operation.inputs}

The list of \lstinline{Tensor} objects representing the data inputs of this
op.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.control_inputs}
}{tf.Operation.control_inputs }}\label{tf.operation.controlux5finputs}

The \lstinline{Operation} objects on which this op has a control
dependency.

Before this op is executed, TensorFlow will ensure that the operations
in \lstinline{self.control_inputs} have finished executing. This mechanism
can be used to run ops sequentially for performance reasons, or to
ensure that the side effects of an op are observed in the correct order.

\subparagraph{Returns: }\label{returns-14}

A list of \lstinline{Operation} objects.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.outputs}
}{tf.Operation.outputs }}\label{tf.operation.outputs}

The list of \lstinline{Tensor} objects representing the outputs of this op.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.device}
}{tf.Operation.device }}\label{tf.operation.device}

The name of the device to which this op has been assigned, if any.

\subparagraph{Returns: }\label{returns-15}

The string name of the device to which this op has been assigned, or
None if it has not been assigned to a device.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.graph}
}{tf.Operation.graph }}\label{tf.operation.graph}

The \lstinline{Graph} that contains this operation.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.run(feed_dict=None, session=None)}
}{tf.Operation.run(feed_dict=None, session=None) }}\label{tf.operation.run}

Runs this operation in a \lstinline{Session}.

Calling this method will execute all preceding operations that produce
the inputs needed for this operation.

\emph{N.B.} Before invoking \lstinline{Operation.run()}, its graph must
have been launched in a session, and either a default session must be
available, or \lstinline{session} must be specified explicitly.

\subparagraph{Args: }\label{args-12}

\begin{itemize}
\tightlist
\item
  \lstinline{feed_dict}: A dictionary that maps \lstinline{Tensor} objects to
  feed values. See
  \href{../../api_docs/python/client.md\#Session.run}{\lstinline{Session.run()}}
  for a description of the valid feed values.
\item
  \lstinline{session}: (Optional.) The \lstinline{Session} to be used to run
  to this operation. If none, the default session will be used.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.get_attr(name)}
}{tf.Operation.get_attr(name) }}\label{tf.operation.getux5fattrname}

Returns the value of the attr of this op with the given \lstinline{name}.

\subparagraph{Args: }\label{args-13}

\begin{itemize}
\tightlist
\item
  \lstinline{name}: The name of the attr to fetch.
\end{itemize}

\subparagraph{Returns: }\label{returns-16}

The value of the attr, as a Python object.

\subparagraph{Raises: }\label{raises-6}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If this op does not have an attr with the given
  \lstinline{name}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.traceback}
}{tf.Operation.traceback }}\label{tf.operation.traceback}

Returns the call stack from when this operation was constructed.

\paragraph{Other Methods }\label{other-methods}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.__init__(node_def, g, inputs=None, output_types=None, control_inputs=None, input_types=None, original_op=None, op_def=None)}
}{tf.Operation.__init__(node_def, g, inputs=None, output_types=None, control_inputs=None, input_types=None, original_op=None, op_def=None) }}\label{tf.operation.ux5fux5finitux5fux5fnodeux5fdef-g-inputsnone-outputux5ftypesnone-controlux5finputsnone-inputux5ftypesnone-originalux5fopnone-opux5fdefnone}

Creates an \lstinline{Operation}.

NOTE: This constructor validates the name of the Operation (passed as
``node_def.name''). Valid Operation names match the following regular
expression:

{[}A-Za-z0-9.{]}{[}A-Za-z0-9_.-/{]}*

\subparagraph{Args: }\label{args-14}

\begin{itemize}
\tightlist
\item
  \lstinline{node_def}: graph_pb2.NodeDef. NodeDef for the Operation.
  Used for attributes of graph_pb2.NodeDef, typically ``name'', ``op'',
  and ``device''. The ``input'' attribute is irrelevant here as it will
  be computed when generating the model.
\item
  \lstinline{g}: Graph. The parent graph.
\item
  \lstinline{inputs}: list of Tensor objects. The inputs to this Operation.
\item
  \lstinline{output_types}: list of types_pb2.DataType. List of the types
  of the Tensors computed by this operation. The length of this list
  indicates the number of output endpoints of the Operation.
\item
  \lstinline{control_inputs}: list of operations or tensors from which to
  have a control dependency.
\item
  \lstinline{input_types}: List of types_pb2.DataType representing the
  types of the Tensors accepted by the Operation. By default uses
  {[}x.dtype.base_dtype for x in inputs{]}. Operations that expect
  reference-typed inputs must specify these explicitly.
\item
  \lstinline{original_op}: Optional. Used to associate the new Operation
  with an existing Operation (for example, a replica with the op that
  was replicated).
\item
  \lstinline{op_def}: Optional. The op_def_pb2.OpDef proto that
  describes the op type that this Operation represents.
\end{itemize}

\subparagraph{Raises: }\label{raises-7}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: if control inputs are not Operations or Tensors,
  or if node_def is not a NodeDef, or if g is not a Graph, or if inputs
  are not Tensors, or if inputs and input_types are incompatible.
\item
  \lstinline{ValueError}: if the node_def name is not valid.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.node_def}
}{tf.Operation.node_def }}\label{tf.operation.nodeux5fdef}

Returns a serialized \lstinline{NodeDef} representation of this operation.

\subparagraph{Returns: }\label{returns-17}

A
\href{https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/framework/graph.proto}{\lstinline{NodeDef}}
protocol buffer.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.op_def}
}{tf.Operation.op_def }}\label{tf.operation.opux5fdef}

Returns the \lstinline{OpDef} proto that represents the type of this op.

\subparagraph{Returns: }\label{returns-18}

An
\href{https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/framework/op_def.proto}{\lstinline{OpDef}}
protocol buffer.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Operation.values()}
}{tf.Operation.values() }}\label{tf.operation.values}

DEPRECATED: Use outputs.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{class tf.Tensor}
}{class tf.Tensor }}\label{class-tf.tensor}

Represents a value produced by an \lstinline{Operation}.

A \lstinline{Tensor} is a symbolic handle to one of the outputs of an
\lstinline{Operation}. It does not hold the values of that operation's
output, but instead provides a means of computing those values in a
TensorFlow
\href{../../api_docs/python/client.md\#Session}{\lstinline{Session}}.

This class has two primary purposes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A \lstinline{Tensor} can be passed as an input to another
  \lstinline{Operation}. This builds a dataflow connection between
  operations, which enables TensorFlow to execute an entire
  \lstinline{Graph} that represents a large, multi-step computation.
\item
  After the graph has been launched in a session, the value of the
  \lstinline{Tensor} can be computed by passing it to
  \href{../../api_docs/python/client.md\#Session.run}{\lstinline{Session.run()}}.
  \lstinline{t.eval()} is a shortcut for calling
  \lstinline{tf.get_default_session().run(t)}.
\end{enumerate}

In the following example, \lstinline{c}, \lstinline{d}, and \lstinline{e} are
symbolic \lstinline{Tensor} objects, whereas \lstinline{result} is a numpy
array that stores a concrete value:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Build a dataflow graph.}
\NormalTok{c }\OperatorTok{=} \NormalTok{tf.constant([[}\FloatTok{1.0}\NormalTok{, }\FloatTok{2.0}\NormalTok{], [}\FloatTok{3.0}\NormalTok{, }\FloatTok{4.0}\NormalTok{]])}
\NormalTok{d }\OperatorTok{=} \NormalTok{tf.constant([[}\FloatTok{1.0}\NormalTok{, }\FloatTok{1.0}\NormalTok{], [}\FloatTok{0.0}\NormalTok{, }\FloatTok{1.0}\NormalTok{]])}
\NormalTok{e }\OperatorTok{=} \NormalTok{tf.matmul(c, d)}

\CommentTok{# Construct a `Session` to execut the graph.}
\NormalTok{sess }\OperatorTok{=} \NormalTok{tf.Session()}

\CommentTok{# Execute the graph and store the value that `e` represents in `result`.}
\NormalTok{result }\OperatorTok{=} \NormalTok{sess.run(e)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.dtype}
}{tf.Tensor.dtype }}\label{tf.tensor.dtype}

The \lstinline{DType} of elements in this tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.name}
}{tf.Tensor.name }}\label{tf.tensor.name}

The string name of this tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.value_index}
}{tf.Tensor.value_index }}\label{tf.tensor.valueux5findex}

The index of this tensor in the outputs of its \lstinline{Operation}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.graph}
}{tf.Tensor.graph }}\label{tf.tensor.graph}

The \lstinline{Graph} that contains this tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.op}
}{tf.Tensor.op }}\label{tf.tensor.op}

The \lstinline{Operation} that produces this tensor as an output.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.consumers()}
}{tf.Tensor.consumers() }}\label{tf.tensor.consumers}

Returns a list of \lstinline{Operation}s that consume this tensor.

\subparagraph{Returns: }\label{returns-19}

A list of \lstinline{Operation}s.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.eval(feed_dict=None, session=None)}
}{tf.Tensor.eval(feed_dict=None, session=None) }}\label{tf.tensor.eval}

Evaluates this tensor in a \lstinline{Session}.

Calling this method will execute all preceding operations that produce
the inputs needed for the operation that produces this tensor.

\emph{N.B.} Before invoking \lstinline{Tensor.eval()}, its graph must have
been launched in a session, and either a default session must be
available, or \lstinline{session} must be specified explicitly.

\subparagraph{Args: }\label{args-15}

\begin{itemize}
\tightlist
\item
  \lstinline{feed_dict}: A dictionary that maps \lstinline{Tensor} objects to
  feed values. See
  \href{../../api_docs/python/client.md\#Session.run}{\lstinline{Session.run()}}
  for a description of the valid feed values.
\item
  \lstinline{session}: (Optional.) The \lstinline{Session} to be used to
  evaluate this tensor. If none, the default session will be used.
\end{itemize}

\subparagraph{Returns: }\label{returns-20}

A numpy array corresponding to the value of this tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.get_shape()}
}{tf.Tensor.get_shape() }}\label{tf.tensor.getux5fshape}

Returns the \lstinline{TensorShape} that represents the shape of this
tensor.

The shape is computed using shape inference functions that are
registered for each \lstinline{Operation} type using
\lstinline{tf.RegisterShape}. See
\href{../../api_docs/python/framework.md\#TensorShape}{\lstinline{TensorShape}}
for more details of what a shape represents.

The inferred shape of a tensor is used to provide shape information
without having to launch the graph in a session. This can be used for
debugging, and providing early error messages. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c }\OperatorTok{=} \NormalTok{tf.constant([[}\FloatTok{1.0}\NormalTok{, }\FloatTok{2.0}\NormalTok{, }\FloatTok{3.0}\NormalTok{], [}\FloatTok{4.0}\NormalTok{, }\FloatTok{5.0}\NormalTok{, }\FloatTok{6.0}\NormalTok{]])}

\BuiltInTok{print} \NormalTok{c.get_shape()}
\OperatorTok{==>} \NormalTok{TensorShape([Dimension(}\DecValTok{2}\NormalTok{), Dimension(}\DecValTok{3}\NormalTok{)])}

\NormalTok{d }\OperatorTok{=} \NormalTok{tf.constant([[}\FloatTok{1.0}\NormalTok{, }\FloatTok{0.0}\NormalTok{], [}\FloatTok{0.0}\NormalTok{, }\FloatTok{1.0}\NormalTok{], [}\FloatTok{1.0}\NormalTok{, }\FloatTok{0.0}\NormalTok{], [}\FloatTok{0.0}\NormalTok{, }\FloatTok{1.0}\NormalTok{]])}

\BuiltInTok{print} \NormalTok{d.get_shape()}
\OperatorTok{==>} \NormalTok{TensorShape([Dimension(}\DecValTok{4}\NormalTok{), Dimension(}\DecValTok{2}\NormalTok{)])}

\CommentTok{# Raises a ValueError, because `c` and `d` do not have compatible}
\CommentTok{# inner dimensions.}
\NormalTok{e }\OperatorTok{=} \NormalTok{tf.matmul(c, d)}

\NormalTok{f }\OperatorTok{=} \NormalTok{tf.matmul(c, d, transpose_a}\OperatorTok{=}\VariableTok{True}\NormalTok{, transpose_b}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\BuiltInTok{print} \NormalTok{f.get_shape()}
\OperatorTok{==>} \NormalTok{TensorShape([Dimension(}\DecValTok{3}\NormalTok{), Dimension(}\DecValTok{4}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

In some cases, the inferred shape may have unknown dimensions. If the
caller has additional information about the values of these dimensions,
\lstinline{Tensor.set_shape()} can be used to augment the inferred shape.

\subparagraph{Returns: }\label{returns-21}

A \lstinline{TensorShape} representing the shape of this tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.set_shape(shape)}
}{tf.Tensor.set_shape(shape) }}\label{tf.tensor.setux5fshapeshape}

Updates the shape of this tensor.

This method can be called multiple times, and will merge the given
\lstinline{shape} with the current shape of this tensor. It can be used to
provide additional information about the shape of this tensor that
cannot be inferred from the graph alone. For example, this can be used
to provide additional information about the shapes of images:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{_, image_data }\OperatorTok{=} \NormalTok{tf.TFRecordReader(...).read(...)}
\NormalTok{image }\OperatorTok{=} \NormalTok{tf.image.decode_png(image_data, channels}\OperatorTok{=}\DecValTok{3}\NormalTok{)}

\CommentTok{# The height and width dimensions of `image` are data dependent, and}
\CommentTok{# cannot be computed without executing the op.}
\BuiltInTok{print} \NormalTok{image.get_shape()}
\OperatorTok{==>} \NormalTok{TensorShape([Dimension(}\VariableTok{None}\NormalTok{), Dimension(}\VariableTok{None}\NormalTok{), Dimension(}\DecValTok{3}\NormalTok{)])}

\CommentTok{# We know that each image in this dataset is 28 x 28 pixels.}
\NormalTok{image.set_shape([}\DecValTok{28}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{3}\NormalTok{])}
\BuiltInTok{print} \NormalTok{image.get_shape()}
\OperatorTok{==>} \NormalTok{TensorShape([Dimension(}\DecValTok{28}\NormalTok{), Dimension(}\DecValTok{28}\NormalTok{), Dimension(}\DecValTok{3}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-16}

\begin{itemize}
\tightlist
\item
  \lstinline{shape}: A \lstinline{TensorShape} representing the shape of this
  tensor.
\end{itemize}

\subparagraph{Raises: }\label{raises-8}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{shape} is not compatible with the
  current shape of this tensor.
\end{itemize}

\paragraph{Other Methods }\label{other-methods-1}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.__init__(op, value_index, dtype)}
}{tf.Tensor.__init__(op, value_index, dtype) }}\label{tf.tensor.ux5fux5finitux5fux5fop-valueux5findex-dtype}

Creates a new \lstinline{Tensor}.

\subparagraph{Args: }\label{args-17}

\begin{itemize}
\tightlist
\item
  \lstinline{op}: An \lstinline{Operation}. \lstinline{Operation} that computes
  this tensor.
\item
  \lstinline{value_index}: An \lstinline{int}. Index of the operation's
  endpoint that produces this tensor.
\item
  \lstinline{dtype}: A \lstinline{types.DType}. Type of data stored in this
  tensor.
\end{itemize}

\subparagraph{Raises: }\label{raises-9}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If the op is not an \lstinline{Operation}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Tensor.device}
}{tf.Tensor.device }}\label{tf.tensor.device}

The name of the device on which this tensor will be produced, or None.

\subsection{Tensor types }\label{tensor-types}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{class tf.DType}
}{class tf.DType }}\label{class-tf.dtype}

Represents the type of the elements in a \lstinline{Tensor}.

The following \lstinline{DType} objects are defined:

\begin{itemize}
\item
  \lstinline{tf.float32}: 32-bit single-precision floating-point.
\item
  \lstinline{tf.float64}: 64-bit double-precision floating-point.
\item
  \lstinline{tf.bfloat16}: 16-bit truncated floating-point.
\item
  \lstinline{tf.complex64}: 64-bit single-precision complex.
\item
  \lstinline{tf.int8}: 8-bit signed integer.
\item
  \lstinline{tf.uint8}: 8-bit unsigned integer.
\item
  \lstinline{tf.int32}: 32-bit signed integer.
\item
  \lstinline{tf.int64}: 64-bit signed integer.
\item
  \lstinline{tf.bool}: Boolean.
\item
  \lstinline{tf.string}: String.
\item
  \lstinline{tf.qint8}: Quantized 8-bit signed integer.
\item
  \lstinline{tf.quint8}: Quantized 8-bit unsigned integer.
\item
  \lstinline{tf.qint32}: Quantized 32-bit signed integer.
\end{itemize}

In addition, variants of these types with the \lstinline{_ref} suffix are
defined for reference-typed tensors.

The \lstinline{tf.as_dtype()} function converts numpy types and string
type names to a \lstinline{DType} object.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.is_compatible_with(other)}
}{tf.DType.is_compatible_with(other) }}\label{tf.dtype.isux5fcompatibleux5fwithother}

Returns True if the \lstinline{other} DType will be converted to this
DType.

The conversion rules are as follows:

\begin{lstlisting}
DType(T)       .is_compatible_with(DType(T))        == True
DType(T)       .is_compatible_with(DType(T).as_ref) == True
DType(T).as_ref.is_compatible_with(DType(T))        == False
DType(T).as_ref.is_compatible_with(DType(T).as_ref) == True
\end{lstlisting}

\subparagraph{Args: }\label{args-18}

\begin{itemize}
\tightlist
\item
  \lstinline{other}: A \lstinline{DType} (or object that may be converted to a
  \lstinline{DType}).
\end{itemize}

\subparagraph{Returns: }\label{returns-22}

True if a Tensor of the \lstinline{other} \lstinline{DType} will be implicitly
converted to this \lstinline{DType}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.name}
}{tf.DType.name }}\label{tf.dtype.name}

Returns the string name for this \lstinline{DType}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.base_dtype}
}{tf.DType.base_dtype }}\label{tf.dtype.baseux5fdtype}

Returns a non-reference \lstinline{DType} based on this \lstinline{DType}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.is_ref_dtype}
}{tf.DType.is_ref_dtype }}\label{tf.dtype.isux5frefux5fdtype}

Returns \lstinline{True} if this \lstinline{DType} represents a reference
type.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.as_ref}
}{tf.DType.as_ref }}\label{tf.dtype.asux5fref}

Returns a reference \lstinline{DType} based on this \lstinline{DType}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.is_integer}
}{tf.DType.is_integer }}\label{tf.dtype.isux5finteger}

Returns whether this is a (non-quantized) integer type.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.is_quantized}
}{tf.DType.is_quantized }}\label{tf.dtype.isux5fquantized}

Returns whether this is a quantized data type.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.as_numpy_dtype}
}{tf.DType.as_numpy_dtype }}\label{tf.dtype.asux5fnumpyux5fdtype}

Returns a \lstinline{numpy.dtype} based on this \lstinline{DType}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.as_datatype_enum}
}{tf.DType.as_datatype_enum }}\label{tf.dtype.asux5fdatatypeux5fenum}

Returns a \lstinline{types_pb2.DataType} enum value based on this
\lstinline{DType}.

\paragraph{Other Methods }\label{other-methods-2}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.__init__(type_enum)}
}{tf.DType.__init__(type_enum) }}\label{tf.dtype.ux5fux5finitux5fux5ftypeux5fenum}

Creates a new \lstinline{DataType}.

NOTE(mrry): In normal circumstances, you should not need to construct a
DataType object directly. Instead, use the types.as_dtype() function.

\subparagraph{Args: }\label{args-19}

\begin{itemize}
\tightlist
\item
  \lstinline{type_enum}: A \lstinline{types_pb2.DataType} enum value.
\end{itemize}

\subparagraph{Raises: }\label{raises-10}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If \lstinline{type_enum} is not a value
  \lstinline{types_pb2.DataType}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.max}
}{tf.DType.max }}\label{tf.dtype.max}

Returns the maximum representable value in this data type.

\subparagraph{Raises: }\label{raises-11}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: if this is a non-numeric, unordered, or quantized
  type.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.DType.min}
}{tf.DType.min }}\label{tf.dtype.min}

Returns the minimum representable value in this data type.

\subparagraph{Raises: }\label{raises-12}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: if this is a non-numeric, unordered, or quantized
  type.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.as_dtype(type_value)}
}{tf.as_dtype(type_value) }}\label{tf.asux5fdtypetypeux5fvalue}

Converts the given \lstinline{type_value} to a \lstinline{DType}.

\subparagraph{Args: }\label{args-20}

\begin{itemize}
\tightlist
\item
  \lstinline{type_value}: A value that can be converted to a
  \lstinline{tf.DType} object. This may currently be a \lstinline{tf.DType}
  object, a
  \href{https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/framework/types.proto}{\lstinline{DataType}
  enum}, a string type name, or a \lstinline{numpy.dtype}.
\end{itemize}

\subparagraph{Returns: }\label{returns-23}

A \lstinline{DType} corresponding to \lstinline{type_value}.

\subparagraph{Raises: }\label{raises-13}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If \lstinline{type_value} cannot be converted to a
  \lstinline{DType}.
\end{itemize}

\subsection{Utility functions }\label{utility-functions}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.device(dev)}
}{tf.device(dev) }}\label{tf.devicedev}

Wrapper for \lstinline{Graph.device()} using the default graph.

See
\href{../../api_docs/python/framework.md\#Graph.name_scope}{\lstinline{Graph.name_scope()}}
for more details.

\subparagraph{Args: }\label{args-21}

\begin{itemize}
\tightlist
\item
  \lstinline{device_name_or_function}: The device name or function to
  use in the context.
\end{itemize}

\subparagraph{Returns: }\label{returns-24}

A context manager that specifies the default device to use for newly
created ops.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.name_scope(name)}
}{tf.name_scope(name) }}\label{tf.nameux5fscopename}

Wrapper for \lstinline{Graph.name_scope()} using the default graph.

See
\href{../../api_docs/python/framework.md\#Graph.name_scope}{\lstinline{Graph.name_scope()}}
for more details.

\subparagraph{Args: }\label{args-22}

\begin{itemize}
\tightlist
\item
  \lstinline{name}: A name for the scope.
\end{itemize}

\subparagraph{Returns: }\label{returns-25}

A context manager that installs \lstinline{name} as a new name scope in the
default graph.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.control_dependencies(control_inputs)}
}{tf.control_dependencies(control_inputs) }}\label{tf.controlux5fdependenciescontrolux5finputs}

Wrapper for \lstinline{Graph.control_dependencies()} using the default
graph.

See
\href{../../api_docs/python/framework.md\#Graph.control_dependencies}{\lstinline{Graph.control_dependencies()}}
for more details.

\subparagraph{Args: }\label{args-23}

\begin{itemize}
\tightlist
\item
  \lstinline{control_inputs}: A list of \lstinline{Operation} or
  \lstinline{Tensor} objects, which must be executed or computed before
  running the operations defined in the context.
\end{itemize}

\subparagraph{Returns: }\label{returns-26}

A context manager that specifies control dependencies for all operations
constructed within the context.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.convert_to_tensor(value, dtype=None, name=None)}
}{tf.convert_to_tensor(value, dtype=None, name=None) }}\label{tf.convertux5ftoux5ftensorvalue-dtypenone-namenone}

Converts the given \lstinline{value} to a \lstinline{Tensor}.

This function converts Python objects of various types to
\lstinline{Tensor} objects. It accepts \lstinline{Tensor} objects, numpy
arrays, Python lists, and Python scalars. For example:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import} \NormalTok{numpy }\ImportTok{as} \NormalTok{np}
\NormalTok{array }\OperatorTok{=} \NormalTok{np.random.rand((}\DecValTok{32}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{100}\NormalTok{))}

\KeywordTok{def} \NormalTok{my_func(arg):}
  \NormalTok{arg }\OperatorTok{=} \NormalTok{tf.convert_to_tensor(arg, dtype}\OperatorTok{=}\NormalTok{tf.float32)}
  \ControlFlowTok{return} \NormalTok{tf.matmul(arg, arg) }\OperatorTok{+} \NormalTok{arg}

\CommentTok{# The following calls are equivalent.}
\NormalTok{value_1 }\OperatorTok{=} \NormalTok{my_func(tf.constant([[}\FloatTok{1.0}\NormalTok{, }\FloatTok{2.0}\NormalTok{], [}\FloatTok{3.0}\NormalTok{, }\FloatTok{4.0}\NormalTok{]]))}
\NormalTok{value_2 }\OperatorTok{=} \NormalTok{my_func([[}\FloatTok{1.0}\NormalTok{, }\FloatTok{2.0}\NormalTok{], [}\FloatTok{3.0}\NormalTok{, }\FloatTok{4.0}\NormalTok{]])}
\NormalTok{value_3 }\OperatorTok{=} \NormalTok{my_func(np.array([[}\FloatTok{1.0}\NormalTok{, }\FloatTok{2.0}\NormalTok{], [}\FloatTok{3.0}\NormalTok{, }\FloatTok{4.0}\NormalTok{]], dtype}\OperatorTok{=}\NormalTok{np.float32))}
\end{Highlighting}
\end{Shaded}

This function can be useful when composing a new operation in Python
(such as \lstinline{my_func} in the example above). All standard Python op
constructors apply this function to each of their Tensor-valued inputs,
which allows those ops to accept numpy arrays, Python lists, and scalars
in addition to \lstinline{Tensor} objects.

\subparagraph{Args: }\label{args-24}

\begin{itemize}
\tightlist
\item
  \lstinline{value}: An object whose type has a registered \lstinline{Tensor}
  conversion function.
\item
  \lstinline{dtype}: Optional element type for the returned tensor. If
  missing, the type is inferred from the type of \lstinline{value}.
\item
  \lstinline{name}: Optional name to use if a new \lstinline{Tensor} is
  created.
\end{itemize}

\subparagraph{Returns: }\label{returns-27}

A \lstinline{Tensor} based on \lstinline{value}.

\subparagraph{Raises: }\label{raises-14}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If no conversion function is registered for
  \lstinline{value}.
\item
  \lstinline{RuntimeError}: If a registered conversion function returns an
  invalid value.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.get_default_graph()}
}{tf.get_default_graph() }}\label{tf.getux5fdefaultux5fgraph}

Returns the default graph for the current thread.

The returned graph will be the innermost graph on which a
\lstinline{Graph.as_default()} context has been entered, or a global
default graph if none has been explicitly created.

\emph{N.B.} The default graph is a property of the current thread. If
you create a new thread, and wish to use the default graph in that
thread, you must explicitly add a \lstinline{with g.as_default():} in
that thread's function.

\subparagraph{Returns: }\label{returns-28}

The default \lstinline{Graph} being used in the current thread.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None)}
}{tf.import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None) }}\label{tf.importux5fgraphux5fdefgraphux5fdef-inputux5fmapnone-returnux5felementsnone-namenone-opux5fdictnone}

Imports the TensorFlow graph in \lstinline{graph_def} into the Python
\lstinline{Graph}.

This function provides a way to import a serialized TensorFlow
\href{https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/framework/graph.proto}{\lstinline{GraphDef}}
protocol buffer, and extract individual objects in the \lstinline{GraphDef}
as \protect\hyperlink{Tensor}{\lstinline{Tensor}} and
\protect\hyperlink{Operation}{\lstinline{Operation}} objects. See
\protect\hyperlink{Graph.asux5fgraphux5fdef}{\lstinline{Graph.as_graph_def()}}
for a way to create a \lstinline{GraphDef} proto.

\subparagraph{Args: }\label{args-25}

\begin{itemize}
\tightlist
\item
  \lstinline{graph_def}: A \lstinline{GraphDef} proto containing operations
  to be imported into the default graph.
\item
  \lstinline{input_map}: A dictionary mapping input names (as strings) in
  \lstinline{graph_def} to \lstinline{Tensor} objects. The values of the
  named input tensors in the imported graph will be re-mapped to the
  respective \lstinline{Tensor} values.
\item
  \lstinline{return_elements}: A list of strings containing operation
  names in \lstinline{graph_def} that will be returned as
  \lstinline{Operation} objects; and/or tensor names in \lstinline{graph_def}
  that will be returned as \lstinline{Tensor} objects.
\item
  \lstinline{name}: (Optional.) A prefix that will be prepended to the
  names in \lstinline{graph_def}. Defaults to \lstinline{"import"}.
\item
  \lstinline{op_dict}: (Optional.) A dictionary mapping op type names to
  \lstinline{OpDef} protos. Must contain an \lstinline{OpDef} proto for each
  op type named in \lstinline{graph_def}. If omitted, uses the
  \lstinline{OpDef} protos registered in the global registry.
\end{itemize}

\subparagraph{Returns: }\label{returns-29}

A list of \lstinline{Operation} and/or \lstinline{Tensor} objects from the
imported graph, corresponding to the names in `return_elements'.

\subparagraph{Raises: }\label{raises-15}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If \lstinline{graph_def} is not a \lstinline{GraphDef}
  proto,
  \lstinline{input_map\textquotesingle{} is not a dictionary mapping strings to}Tensor\lstinline{objects, or}return_elements`
  is not a list of strings.
\item
  \lstinline{ValueError}: If \lstinline{input_map}, or
  \lstinline{return_elements} contains names that do not appear in
  \lstinline{graph_def}, or \lstinline{graph_def} is not well-formed
  (e.g.~it refers to an unknown tensor).
\end{itemize}

\subsection{Graph collections }\label{graph-collections}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.add_to_collection(name, value)}
}{tf.add_to_collection(name, value) }}\label{tf.addux5ftoux5fcollectionname-value}

Wrapper for \lstinline{Graph.add_to_collection()} using the default
graph.

See
\href{../../api_docs/python/framework.md\#Graph.add_to_collection}{\lstinline{Graph.add_to_collection()}}
for more details.

\subparagraph{Args: }\label{args-26}

\begin{itemize}
\tightlist
\item
  \lstinline{name}: The key for the collection. For example, the
  \lstinline{GraphKeys} class contains many standard names for collections.
\item
  \lstinline{value}: The value to add to the collection.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.get_collection(key, scope=None)}
}{tf.get_collection(key, scope=None) }}\label{tf.getux5fcollectionkey-scopenone}

Wrapper for \lstinline{Graph.get_collection()} using the default graph.

See
\href{../../api_docs/python/framework.md\#Graph.get_collection}{\lstinline{Graph.get_collection()}}
for more details.

\subparagraph{Args: }\label{args-27}

\begin{itemize}
\tightlist
\item
  \lstinline{key}: The key for the collection. For example, the
  \lstinline{GraphKeys} class contains many standard names for collections.
\item
  \lstinline{scope}: (Optional.) If supplied, the resulting list is
  filtered to include only items whose name begins with this string.
\end{itemize}

\subparagraph{Returns: }\label{returns-30}

The list of values in the collection with the given \lstinline{name}, or an
empty list if no value has been added to that collection. The list
contains the values in the order under which they were collected.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{class tf.GraphKeys}
}{class tf.GraphKeys }}\label{class-tf.graphkeys}

Standard names to use for graph collections.

The standard library uses various well-known names to collect and
retrieve values associated with a graph. For example, the
\lstinline{tf.Optimizer} subclasses default to optimizing the variables
collected under \lstinline{tf.GraphKeys.TRAINABLE_VARIABLES} if none is
specified, but it is also possible to pass an explicit list of
variables.

The following standard keys are defined:

\begin{itemize}
\tightlist
\item
  \lstinline{VARIABLES}: the \lstinline{Variable} objects that comprise a
  model, and must be saved and restored together. See
  \href{../../api_docs/python/state_ops.md\#all_variables}{\lstinline{tf.all_variables()}}
  for more details.
\item
  \lstinline{TRAINABLE_VARIABLES}: the subset of \lstinline{Variable} objects
  that will be trained by an optimizer. See
  \href{../../api_docs/python/state_ops.md\#trainable_variables}{\lstinline{tf.trainable_variables()}}
  for more details.
\item
  \lstinline{SUMMARIES}: the summary \lstinline{Tensor} objects that have been
  created in the graph. See
  \href{../../api_docs/python/train.md\#merge_all_summaries}{\lstinline{tf.merge_all_summaries()}}
  for more details.
\item
  \lstinline{QUEUE_RUNNERS}: the \lstinline{QueueRunner} objects that are
  used to produce input for a computation. See
  \href{../../api_docs/python/train.md\#start_queue_runners}{\lstinline{tf.start_queue_runners()}}
  for more details.
\end{itemize}

\subsection{Defining new operations }\label{defining-new-operations}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{class tf.RegisterGradient}
}{class tf.RegisterGradient }}\label{class-tf.registergradient}

A decorator for registering the gradient function for an op type.

This decorator is only used when defining a new op type. For an op with
\lstinline{m} inputs and \lstinline{n} inputs, the gradient function is a
function that takes the original \lstinline{Operation} and \lstinline{n}
\lstinline{Tensor} objects (representing the gradients with respect to each
output of the op), and returns \lstinline{m} \lstinline{Tensor} objects
(representing the partial gradients with respect to each input of the
op).

For example, assuming that operations of type \lstinline{"Sub"} take two
inputs \lstinline{x} and \lstinline{y}, and return a single output
\lstinline{x - y}, the following gradient function would be registered:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{@tf.RegisterGradient}\NormalTok{(}\StringTok{"Sub"}\NormalTok{)}
\KeywordTok{def} \NormalTok{_sub_grad(unused_op, grad):}
  \ControlFlowTok{return} \NormalTok{grad, tf.Neg(grad)}
\end{Highlighting}
\end{Shaded}

The decorator argument \lstinline{op_type} is the string type of an
operation. This corresponds to the \lstinline{OpDef.name} field for the
proto that defines the operation.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.RegisterGradient.__init__(op_type)}
}{tf.RegisterGradient.__init__(op_type) }}\label{tf.registergradient.ux5fux5finitux5fux5fopux5ftype}

Creates a new decorator with \lstinline{op_type} as the Operation type.

\subparagraph{Args: }\label{args-28}

\begin{itemize}
\tightlist
\item
  \lstinline{op_type}: The string type of an operation. This corresponds
  to the \lstinline{OpDef.name} field for the proto that defines the
  operation.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.NoGradient(op_type)}
}{tf.NoGradient(op_type) }}\label{tf.nogradientopux5ftype}

Specifies that ops of type \lstinline{op_type} do not have a defined
gradient.

This function is only used when defining a new op type. It may be used
for ops such as \lstinline{tf.size()} that are not differentiable. For
example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf.NoGradient(}\StringTok{"Size"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-29}

\begin{itemize}
\tightlist
\item
  \lstinline{op_type}: The string type of an operation. This corresponds
  to the \lstinline{OpDef.name} field for the proto that defines the
  operation.
\end{itemize}

\subparagraph{Raises: }\label{raises-16}

\begin{itemize}
\tightlist
\item
  \lstinline{TypeError}: If \lstinline{op_type} is not a string.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{class tf.RegisterShape}
}{class tf.RegisterShape }}\label{class-tf.registershape}

A decorator for registering the shape function for an op type.

This decorator is only used when defining a new op type. A shape
function is a function from an \lstinline{Operation} object to a list of
\lstinline{TensorShape} objects, with one \lstinline{TensorShape} for each
output of the operation.

For example, assuming that operations of type \lstinline{"Sub"} take two
inputs \lstinline{x} and \lstinline{y}, and return a single output
\lstinline{x - y}, all with the same shape, the following shape function
would be registered:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{@tf.RegisterShape}\NormalTok{(}\StringTok{"Sub"}\NormalTok{)}
\KeywordTok{def} \NormalTok{_sub_shape(op):}
  \ControlFlowTok{return} \NormalTok{[op.inputs[}\DecValTok{0}\NormalTok{].get_shape().merge_with(op.inputs[}\DecValTok{1}\NormalTok{].get_shape())]}
\end{Highlighting}
\end{Shaded}

The decorator argument \lstinline{op_type} is the string type of an
operation. This corresponds to the \lstinline{OpDef.name} field for the
proto that defines the operation. - - -

\paragraph{\texorpdfstring{\lstinline{tf.RegisterShape.__init__(op_type)}
}{tf.RegisterShape.__init__(op_type) }}\label{tf.registershape.ux5fux5finitux5fux5fopux5ftype}

Saves the ``op_type'' as the Operation type.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{class tf.TensorShape}
}{class tf.TensorShape }}\label{class-tf.tensorshape}

Represents the shape of a \lstinline{Tensor}.

A \lstinline{TensorShape} represents a possibly-partial shape specification
for a \lstinline{Tensor}. It may be one of the following:

\begin{itemize}
\tightlist
\item
  \emph{Fully-known shape:} has a known number of dimensions and a known
  size for each dimension.
\item
  \emph{Partially-known shape:} has a known number of dimensions, and an
  unknown size for one or more dimension.
\item
  \emph{Unknown shape:} has an unknown number of dimensions, and an
  unknown size in all dimensions.
\end{itemize}

If a tensor is produced by an operation of type \lstinline{"Foo"}, its
shape may be inferred if there is a registered shape function for
\lstinline{"Foo"}. See
\href{../../api_docs/python/framework.md\#RegisterShape}{\lstinline{tf.RegisterShape()}}
for details of shape functions and how to register them. Alternatively,
the shape may be set explicitly using
\href{../../api_docs/python/framework.md\#Tensor.set_shape}{\lstinline{Tensor.set_shape()}}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.merge_with(other)}
}{tf.TensorShape.merge_with(other) }}\label{tf.tensorshape.mergeux5fwithother}

Returns a \lstinline{TensorShape} combining the information in
\lstinline{self} and \lstinline{other}.

The dimensions in \lstinline{self} and \lstinline{other} are merged
elementwise, according to the rules defined for
\lstinline{Dimension.merge_with()}.

\subparagraph{Args: }\label{args-30}

\begin{itemize}
\tightlist
\item
  \lstinline{other}: Another \lstinline{TensorShape}.
\end{itemize}

\subparagraph{Returns: }\label{returns-31}

A \lstinline{TensorShape} containing the combined information of
\lstinline{self} and \lstinline{other}.

\subparagraph{Raises: }\label{raises-17}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} and \lstinline{other} are not
  compatible.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.concatenate(other)}
}{tf.TensorShape.concatenate(other) }}\label{tf.tensorshape.concatenateother}

Returns the concatenation of the dimension in \lstinline{self} and
\lstinline{other}.

\emph{N.B.} If either \lstinline{self} or \lstinline{other} is completely
unknown, concatenation will discard information about the other shape.
In future, we might support concatenation that preserves this
information for use with slicing.

\subparagraph{Args: }\label{args-31}

\begin{itemize}
\tightlist
\item
  \lstinline{other}: Another \lstinline{TensorShape}.
\end{itemize}

\subparagraph{Returns: }\label{returns-32}

A \lstinline{TensorShape} whose dimensions are the concatenation of the
dimensions in \lstinline{self} and \lstinline{other}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.ndims}
}{tf.TensorShape.ndims }}\label{tf.tensorshape.ndims}

Returns the rank of this shape, or None if it is unspecified.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.dims}
}{tf.TensorShape.dims }}\label{tf.tensorshape.dims}

Returns a list of Dimensions, or None if the shape is unspecified.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.as_list()}
}{tf.TensorShape.as_list() }}\label{tf.tensorshape.asux5flist}

Returns a list of integers or None for each dimension.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.is_compatible_with(other)}
}{tf.TensorShape.is_compatible_with(other) }}\label{tf.tensorshape.isux5fcompatibleux5fwithother}

Returns True iff \lstinline{self} is compatible with \lstinline{other}.

Two possibly-partially-defined shapes are compatible if there exists a
fully-defined shape that both shapes can represent. Thus, compatibility
allows the shape inference code to reason about partially-defined
shapes. For example:

\begin{itemize}
\item
  TensorShape(None) is compatible with all shapes.
\item
  TensorShape({[}None, None{]}) is compatible with all two-dimensional
  shapes, such as TensorShape({[}32, 784{]}), and also
  TensorShape(None). It is not compatible with, for example,
  TensorShape({[}None{]}) or TensorShape({[}None, None, None{]}).
\item
  TensorShape({[}32, None{]}) is compatible with all two-dimensional
  shapes with size 32 in the 0th dimension, and also
  TensorShape({[}None, None{]}) and TensorShape(None). It is not
  compatible with, for example, TensorShape({[}32{]}),
  TensorShape({[}32, None, 1{]}) or TensorShape({[}64, None{]}).
\item
  TensorShape({[}32, 784{]}) is compatible with itself, and also
  TensorShape({[}32, None{]}), TensorShape({[}None, 784{]}),
  TensorShape({[}None, None{]}) and TensorShape(None). It is not
  compatible with, for example, TensorShape({[}32, 1, 784{]}) or
  TensorShape({[}None{]}).
\end{itemize}

The compatibility relation is reflexive and symmetric, but not
transitive. For example, TensorShape({[}32, 784{]}) is compatible with
TensorShape(None), and TensorShape(None) is compatible with
TensorShape({[}4, 4{]}), but TensorShape({[}32, 784{]}) is not
compatible with TensorShape({[}4, 4{]}).

\subparagraph{Args: }\label{args-32}

\begin{itemize}
\tightlist
\item
  \lstinline{other}: Another TensorShape.
\end{itemize}

\subparagraph{Returns: }\label{returns-33}

True iff \lstinline{self} is compatible with \lstinline{other}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.is_fully_defined()}
}{tf.TensorShape.is_fully_defined() }}\label{tf.tensorshape.isux5ffullyux5fdefined}

Returns True iff \lstinline{self} is fully defined in every dimension.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.with_rank(rank)}
}{tf.TensorShape.with_rank(rank) }}\label{tf.tensorshape.withux5frankrank}

Returns a shape based on \lstinline{self} with the given rank.

This method promotes a completely unknown shape to one with a known
rank.

\subparagraph{Args: }\label{args-33}

\begin{itemize}
\tightlist
\item
  \lstinline{rank}: An integer.
\end{itemize}

\subparagraph{Returns: }\label{returns-34}

A shape that is at least as specific as \lstinline{self} with the given
rank.

\subparagraph{Raises: }\label{raises-18}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} does not represent a shape with
  the given \lstinline{rank}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.with_rank_at_least(rank)}
}{tf.TensorShape.with_rank_at_least(rank) }}\label{tf.tensorshape.withux5frankux5fatux5fleastrank}

Returns a shape based on \lstinline{self} with at least the given rank.

\subparagraph{Args: }\label{args-34}

\begin{itemize}
\tightlist
\item
  \lstinline{rank}: An integer.
\end{itemize}

\subparagraph{Returns: }\label{returns-35}

A shape that is at least as specific as \lstinline{self} with at least the
given rank.

\subparagraph{Raises: }\label{raises-19}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} does not represent a shape with
  at least the given \lstinline{rank}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.with_rank_at_most(rank)}
}{tf.TensorShape.with_rank_at_most(rank) }}\label{tf.tensorshape.withux5frankux5fatux5fmostrank}

Returns a shape based on \lstinline{self} with at most the given rank.

\subparagraph{Args: }\label{args-35}

\begin{itemize}
\tightlist
\item
  \lstinline{rank}: An integer.
\end{itemize}

\subparagraph{Returns: }\label{returns-36}

A shape that is at least as specific as \lstinline{self} with at most the
given rank.

\subparagraph{Raises: }\label{raises-20}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} does not represent a shape with
  at most the given \lstinline{rank}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.assert_has_rank(rank)}
}{tf.TensorShape.assert_has_rank(rank) }}\label{tf.tensorshape.assertux5fhasux5frankrank}

Raises an exception if \lstinline{self} is not compatible with the given
\lstinline{rank}.

\subparagraph{Args: }\label{args-36}

\begin{itemize}
\tightlist
\item
  \lstinline{rank}: An integer.
\end{itemize}

\subparagraph{Raises: }\label{raises-21}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} does not represent a shape with
  the given \lstinline{rank}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.assert_same_rank(other)}
}{tf.TensorShape.assert_same_rank(other) }}\label{tf.tensorshape.assertux5fsameux5frankother}

Raises an exception if \lstinline{self} and \lstinline{other} do not have
compatible ranks.

\subparagraph{Args: }\label{args-37}

\begin{itemize}
\tightlist
\item
  \lstinline{other}: Another \lstinline{TensorShape}.
\end{itemize}

\subparagraph{Raises: }\label{raises-22}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} and \lstinline{other} do not
  represent shapes with the same rank.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.assert_is_compatible_with(other)}
}{tf.TensorShape.assert_is_compatible_with(other) }}\label{tf.tensorshape.assertux5fisux5fcompatibleux5fwithother}

Raises exception if \lstinline{self} and \lstinline{other} do not represent
the same shape.

This method can be used to assert that there exists a shape that both
\lstinline{self} and \lstinline{other} represent.

\subparagraph{Args: }\label{args-38}

\begin{itemize}
\tightlist
\item
  \lstinline{other}: Another TensorShape.
\end{itemize}

\subparagraph{Raises: }\label{raises-23}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} and \lstinline{other} do not
  represent the same shape.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.assert_is_fully_defined()}
}{tf.TensorShape.assert_is_fully_defined() }}\label{tf.tensorshape.assertux5fisux5ffullyux5fdefined}

Raises an exception if \lstinline{self} is not fully defined in every
dimension.

\subparagraph{Raises: }\label{raises-24}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} does not have a known value for
  every dimension.
\end{itemize}

\paragraph{Other Methods }\label{other-methods-3}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.__init__(dims)}
}{tf.TensorShape.__init__(dims) }}\label{tf.tensorshape.ux5fux5finitux5fux5fdims}

Creates a new TensorShape with the given dimensions.

\subparagraph{Args: }\label{args-39}

\begin{itemize}
\tightlist
\item
  \lstinline{dims}: A list of Dimensions, or None if the shape is
  unspecified.
\item
  \lstinline{DEPRECATED}: A single integer is treated as a singleton list.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.as_dimension_list()}
}{tf.TensorShape.as_dimension_list() }}\label{tf.tensorshape.asux5fdimensionux5flist}

DEPRECATED: use as_list().

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.TensorShape.num_elements()}
}{tf.TensorShape.num_elements() }}\label{tf.tensorshape.numux5felements}

Returns the total number of elements, or none for incomplete shapes.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{class tf.Dimension}
}{class tf.Dimension }}\label{class-tf.dimension}

Represents the value of one dimension in a TensorShape. - - -

\paragraph{\texorpdfstring{\lstinline{tf.Dimension.__init__(value)}
}{tf.Dimension.__init__(value) }}\label{tf.dimension.ux5fux5finitux5fux5fvalue}

Creates a new Dimension with the given value.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Dimension.assert_is_compatible_with(other)}
}{tf.Dimension.assert_is_compatible_with(other) }}\label{tf.dimension.assertux5fisux5fcompatibleux5fwithother}

Raises an exception if \lstinline{other} is not compatible with this
Dimension.

\subparagraph{Args: }\label{args-40}

\begin{itemize}
\tightlist
\item
  \lstinline{other}: Another Dimension.
\end{itemize}

\subparagraph{Raises: }\label{raises-25}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} and \lstinline{other} are not
  compatible (see is_compatible_with).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Dimension.is_compatible_with(other)}
}{tf.Dimension.is_compatible_with(other) }}\label{tf.dimension.isux5fcompatibleux5fwithother}

Returns true if \lstinline{other} is compatible with this Dimension.

Two known Dimensions are compatible if they have the same value. An
unknown Dimension is compatible with all other Dimensions.

\subparagraph{Args: }\label{args-41}

\begin{itemize}
\tightlist
\item
  \lstinline{other}: Another Dimension.
\end{itemize}

\subparagraph{Returns: }\label{returns-37}

True if this Dimension and \lstinline{other} are compatible.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Dimension.merge_with(other)}
}{tf.Dimension.merge_with(other) }}\label{tf.dimension.mergeux5fwithother}

Returns a Dimension that combines the information in \lstinline{self} and
\lstinline{other}.

Dimensions are combined as follows:

Dimension(n) .merge_with(Dimension(n)) == Dimension(n) Dimension(n)
.merge_with(Dimension(None)) == Dimension(n)
Dimension(None).merge_with(Dimension(n)) == Dimension(n)
Dimension(None).merge_with(Dimension(None)) == Dimension(None)
Dimension(n) .merge_with(Dimension(m)) raises ValueError for n != m

\subparagraph{Args: }\label{args-42}

\begin{itemize}
\tightlist
\item
  \lstinline{other}: Another Dimension.
\end{itemize}

\subparagraph{Returns: }\label{returns-38}

A Dimension containing the combined information of \lstinline{self} and
\lstinline{other}.

\subparagraph{Raises: }\label{raises-26}

\begin{itemize}
\tightlist
\item
  \lstinline{ValueError}: If \lstinline{self} and \lstinline{other} are not
  compatible (see is_compatible_with).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\paragraph{\texorpdfstring{\lstinline{tf.Dimension.value}
}{tf.Dimension.value }}\label{tf.dimension.value}

The value of this dimension, or None if it is unknown.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.op_scope(values, name, default_name)}
}{tf.op_scope(values, name, default_name) }}\label{tf.opux5fscopevalues-name-defaultux5fname}

Returns a context manager for use when defining a Python op.

This context manager validates that the given \lstinline{values} are from
the same graph, ensures that that graph is the default graph, and pushes
a name scope.

For example, to define a new Python op called \lstinline{my_op}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def} \NormalTok{my_op(a, b, c, name}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
  \ControlFlowTok{with} \NormalTok{tf.op_scope([a, b, c], name, }\StringTok{"MyOp"}\NormalTok{) }\ImportTok{as} \NormalTok{scope:}
    \NormalTok{a }\OperatorTok{=} \NormalTok{tf.convert_to_tensor(a, name}\OperatorTok{=}\StringTok{"a"}\NormalTok{)}
    \NormalTok{b }\OperatorTok{=} \NormalTok{tf.convert_to_tensor(b, name}\OperatorTok{=}\StringTok{"b"}\NormalTok{)}
    \NormalTok{c }\OperatorTok{=} \NormalTok{tf.convert_to_tensor(c, name}\OperatorTok{=}\StringTok{"c"}\NormalTok{)}
    \CommentTok{# Define some computation that uses `a`, `b`, and `c`.}
    \ControlFlowTok{return} \NormalTok{foo_op(..., name}\OperatorTok{=}\NormalTok{scope)}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-43}

\begin{itemize}
\tightlist
\item
  \lstinline{values}: The list of \lstinline{Tensor} arguments that are passed
  to the op function.
\item
  \lstinline{name}: The name argument that is passed to the op function.
\item
  \lstinline{default_name}: The default name to use if the \lstinline{name}
  argument is \lstinline{None}.
\end{itemize}

\subparagraph{Returns: }\label{returns-39}

A context manager for use in defining a Python op.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\lstinline{tf.get_seed(op_seed)}
}{tf.get_seed(op_seed) }}\label{tf.getux5fseedopux5fseed}

Returns the local seeds an operation should use given an op-specific
seed.

Given operation-specific seed, \lstinline{op_seed}, this helper function
returns two seeds derived from graph-level and op-level seeds. Many
random operations internally use the two seeds to allow user to change
the seed globally for a graph, or for only specific operations.

For details on how the graph-level seed interacts with op seeds, see
\href{../../api_docs/python/constant_op.md\#set_random_seed}{\lstinline{set_random_seed}}.

\subparagraph{Args: }\label{args-44}

\begin{itemize}
\tightlist
\item
  \lstinline{op_seed}: integer.
\end{itemize}

\subparagraph{Returns: }\label{returns-40}

A tuple of two integers that should be used for the local seed of this
operation.

